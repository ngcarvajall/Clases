{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"https://github.com/Hack-io-Data/Imagenes/blob/main/01-LogosHackio/logo_naranja@4x.png?raw=true\" alt=\"esquema\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Tabla de Contenidos<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introducci√≥n-a-Pandas\" data-toc-modified-id=\"Introducci√≥n-a-Pandas-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introducci√≥n a Pandas</a></span><ul class=\"toc-item\"><li><span><a href=\"#¬øQu√©-es-Pandas-y-por-qu√©-es-importante?\" data-toc-modified-id=\"¬øQu√©-es-Pandas-y-por-qu√©-es-importante?-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>¬øQu√© es Pandas y por qu√© es importante?</a></span></li></ul></li><li><span><a href=\"#Series-de-Pandas\" data-toc-modified-id=\"Series-de-Pandas-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Series de Pandas</a></span><ul class=\"toc-item\"><li><span><a href=\"#¬øQu√©-es-una-Serie?\" data-toc-modified-id=\"¬øQu√©-es-una-Serie?-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>¬øQu√© es una Serie?</a></span></li><li><span><a href=\"#Creaci√≥n-de-Series\" data-toc-modified-id=\"Creaci√≥n-de-Series-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Creaci√≥n de Series</a></span></li><li><span><a href=\"#Propiedades-de-las-Series\" data-toc-modified-id=\"Propiedades-de-las-Series-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Propiedades de las Series</a></span></li><li><span><a href=\"#Indexaci√≥n-de-las-Series\" data-toc-modified-id=\"Indexaci√≥n-de-las-Series-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Indexaci√≥n de las Series</a></span></li></ul></li><li><span><a href=\"#DataFrames-en-Pandas\" data-toc-modified-id=\"DataFrames-en-Pandas-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>DataFrames en Pandas</a></span><ul class=\"toc-item\"><li><span><a href=\"#¬øQu√©-es-un-DataFrame?\" data-toc-modified-id=\"¬øQu√©-es-un-DataFrame?-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>¬øQu√© es un DataFrame?</a></span></li><li><span><a href=\"#Creaci√≥n-de-DataFrames\" data-toc-modified-id=\"Creaci√≥n-de-DataFrames-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Creaci√≥n de DataFrames</a></span></li><li><span><a href=\"#Lectura-de-archivos-en-Pandas\" data-toc-modified-id=\"Lectura-de-archivos-en-Pandas-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Lectura de archivos en Pandas</a></span></li><li><span><a href=\"#pd.read_csv():\" data-toc-modified-id=\"pd.read_csv():-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span><code>pd.read_csv()</code>:</a></span></li><li><span><a href=\"#pd.read_excel()\" data-toc-modified-id=\"pd.read_excel()-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span><code>pd.read_excel()</code></a></span></li><li><span><a href=\"#pd.read_json()\" data-toc-modified-id=\"pd.read_json()-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span><code>pd.read_json()</code></a></span></li><li><span><a href=\"#pd.read_pickle\" data-toc-modified-id=\"pd.read_pickle-3.7\"><span class=\"toc-item-num\">3.7&nbsp;&nbsp;</span><code>pd.read_pickle</code></a></span></li><li><span><a href=\"#Indexaci√≥n-en-Pandas-(loc-e-iloc)\" data-toc-modified-id=\"Indexaci√≥n-en-Pandas-(loc-e-iloc)-3.8\"><span class=\"toc-item-num\">3.8&nbsp;&nbsp;</span>Indexaci√≥n en Pandas (<code>loc</code> e <code>iloc</code>)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Selecci√≥n-a-trav√©s-de-un-√∫nico-elemento\" data-toc-modified-id=\"Selecci√≥n-a-trav√©s-de-un-√∫nico-elemento-3.8.1\"><span class=\"toc-item-num\">3.8.1&nbsp;&nbsp;</span>Selecci√≥n a trav√©s de un √∫nico elemento</a></span></li><li><span><a href=\"#Selecci√≥n-a-trav√©s-de-una-lista-de-valores\" data-toc-modified-id=\"Selecci√≥n-a-trav√©s-de-una-lista-de-valores-3.8.2\"><span class=\"toc-item-num\">3.8.2&nbsp;&nbsp;</span>Selecci√≥n a trav√©s de una lista de valores</a></span></li><li><span><a href=\"#Selecci√≥n-de-un-rango-de-datos-a-trav√©s-de-un-corte\" data-toc-modified-id=\"Selecci√≥n-de-un-rango-de-datos-a-trav√©s-de-un-corte-3.8.3\"><span class=\"toc-item-num\">3.8.3&nbsp;&nbsp;</span>Selecci√≥n de un rango de datos a trav√©s de un corte</a></span></li><li><span><a href=\"#Seleccionar-basado-en-una-condici√≥n\" data-toc-modified-id=\"Seleccionar-basado-en-una-condici√≥n-3.8.4\"><span class=\"toc-item-num\">3.8.4&nbsp;&nbsp;</span>Seleccionar basado en una condici√≥n</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducci√≥n a Pandas\n",
    "\n",
    "## ¬øQu√© es Pandas y por qu√© es importante?\n",
    "\n",
    "`Pandas` es una biblioteca de Python utilizada para el an√°lisis de datos y la manipulaci√≥n de estructuras de datos tabulares, es decir, en formato de tablas. Nos ofrece una gran cantidad de funciones y herramientas para trabajar con datos de forma eficiente y efectiva. Algunas de las razones por las que Pandas es importante son:\n",
    "\n",
    "- Define nuevas estructuras de datos basadas en los **array*s* de la biblioteca NumPy, pero con funcionalidades adicionales. Esto significa que podemos aprovechar las capacidades de NumPy y agregar nuevas funcionalidades espec√≠ficas para el an√°lisis de datos.\n",
    "  \n",
    "- Permite la carga y manipulaci√≥n de datos de diferentes fuentes, como archivos CSV, Excel, bases de datos SQL, entre otros.\n",
    "  \n",
    "- Proporciona funciones para explorar y entender r√°pidamente la estructura y contenido de los datos.\n",
    "\n",
    "- Facilita la limpieza y transformaci√≥n de datos, lo que es fundamental para garantizar la calidad de los datos antes del an√°lisis.\n",
    "\n",
    "- Ofrece herramientas para realizar an√°lisis estad√≠sticos, visualizaciones y modelado de datos.\n",
    "\n",
    "- Permite acceder a los datos mediante √≠ndices o nombres para filas y columnas. Esto significa que puedes acceder a los datos utilizando etiquetas en lugar de solo posiciones num√©ricas, lo cual es especialmente √∫til cuando los datos est√°n etiquetados o indexados de manera significativa.\n",
    "\n",
    "- Ofrece m√©todos para reordenar, dividir y combinar conjuntos de datos. Puedes realizar operaciones como clasificaci√≥n, filtrado y combinaci√≥n de datos para obtener resultados espec√≠ficos o realizar an√°lisis m√°s avanzados.\n",
    "\n",
    "En cuanto a las estructuras de datos en Pandas, existen tres principales:\n",
    "\n",
    "1. `Series`: Representa una estructura de datos unidimensional similar a un *array* o una columna en una tabla. Cada elemento en una Serie tiene un √≠ndice asociado que permite acceder a los datos de forma individual.\n",
    "\n",
    "\n",
    "2. `DataFrame`: Representa una estructura de datos bidimensional similar a una tabla de una base de datos o una hoja de c√°lculo de Excel. Consiste en una colecci√≥n de Series organizadas en columnas. Los *DataFrame*s son especialmente √∫tiles para el an√°lisis de datos tabulares y ofrecen una gran cantidad de funcionalidades para manipular y analizar los datos.\n",
    "\n",
    "\n",
    "3. `Panel`: Representa una estructura de datos tridimensional, aunque su uso no es tan com√∫n como las *Series* y los *DataFrame*s. Puede considerarse como una colecci√≥n de *DataFrame*s.\n",
    "\n",
    "Antes de ponernos a trabajar con Pandas, lo primero que tendremos que hacer es instalar la librer√≠a usando `pip` o `pip3`: \n",
    "\n",
    "```bash\n",
    "pip install pandas\n",
    "\n",
    "pip3 install pandas\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamiento de datos\n",
    "# ==============================================================================\n",
    "import pandas as pd\n",
    "\n",
    "# Ignorar warnings\n",
    "# ==============================================================================\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# Configuraci√≥n\n",
    "# -----------------------------------------------------------------------\n",
    "pd.set_option('display.max_columns', None) # para poder visualizar todas las columnas de los DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Series de Pandas\n",
    "\n",
    "## ¬øQu√© es una Serie?\n",
    "\n",
    "\n",
    "Como hemos dicho, una **Serie** es una estructura de datos unidimensional en **Pandas**. Se puede pensar en una **Serie** como una columna en una tabla  con etiquetas de √≠ndice. Cada elemento en una **Serie** tiene un √≠ndice asociado que permite acceder a los datos de forma individual.\n",
    "\n",
    "Las Series en Pandas tienen las siguientes caracter√≠sticas:\n",
    "\n",
    "1. **Datos homog√©neos**: Contiene datos de **un solo tipo**, como *integer*s, *float*s, *strings*, etc. \n",
    "\n",
    "2. **√çndices etiquetados**: Cada elemento en una **Serie** tiene una etiqueta de √≠ndice asociada. Los √≠ndices pueden ser etiquetas personalizadas o valores num√©ricos generados autom√°ticamente. Estas etiquetas permiten un acceso m√°s intuitivo a los datos en lugar de depender solo de las posiciones num√©ricas.\n",
    "\n",
    "3. **Funcionalidades adicionales**: Proporcionan numerosas funcionalidades para manipular y analizar datos de manera eficiente. Puedes realizar operaciones matem√°ticas, filtrado de datos, agregaci√≥n, ordenamiento, alineaci√≥n de datos, entre otras.\n",
    "\n",
    "Es importante destacar que las **Series** y los **DataFrames** son los elementos fundamentales en el ecosistema de Pandas, y muchas operaciones de an√°lisis de datos se realizan utilizando estas estructuras de datos.\n",
    "\n",
    "\n",
    "## Creaci√≥n de Series\n",
    "\n",
    "Podemos crear Series de distintas formas: \n",
    "\n",
    "- Series vac√≠as.\n",
    "\n",
    "- Series a partir de un **array**. Recordamos, las **Series** son unidimensionales, por lo tanto solo le podremos pasar **array*s* unidimensionales.\n",
    "\n",
    "- Series a partir de listas.\n",
    "\n",
    "- Series a partir de un diccionario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------ SERIES VAC√çAS ------ \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], dtype: object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creemos algunas Series en Pandas para entenderlas mejor.\n",
    "# en este primer ejemplo crearemos una Serie vac√≠a\n",
    "\n",
    "print(\" ------ SERIES VAC√çAS ------ \")\n",
    "serie_vacia = pd.Series()\n",
    "serie_vacia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------ SERIES a partir de LISTAS ------ \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    109\n",
       "1     78\n",
       "2      4\n",
       "3    189\n",
       "4     98\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\" ------ SERIES a partir de LISTAS ------ \")\n",
    "\n",
    "# definimos la lista\n",
    "lista = [109,78, 4, 189, 98]\n",
    "\n",
    "# convertimos esta lista en una Serie\n",
    "serie_lista1 = pd.Series(lista)\n",
    "serie_lista1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìå Si nos fijamos el m√©todo `pd.Series` nos va a generar autom√°ticamente el √≠ndice y lo crea con n√∫meros consecutivos, empezando por el 0. Sin embargo, tambi√©n le podemos pasar los √≠ndices que queremos usando el par√°metro `index`. Tener √≠ndices personalizados puede ser √∫til cuando necesitamos acceder a los elementos de la **Serie** utilizando etiquetas espec√≠ficas en lugar de las posiciones num√©ricas predeterminadas. Esto facilita la manipulaci√≥n y el an√°lisis de los datos. \n",
    "\n",
    "\n",
    "\n",
    "> index: Es un par√°metro opcional de la funci√≥n `pd.Series`. En este caso, se proporciona una lista de √≠ndices personalizados para la Serie. Los √≠ndices indican c√≥mo se etiquetar√°n los elementos de la Serie. En este ejemplo, los √≠ndices se definen en el orden especificado: 3, 4, 5, 6, 7, 8, 9, 1, 2.\n",
    ">\n",
    "> Es importante destacar que los √≠ndices pueden ser de diferentes tipos, incluidos *integer*s, cadenas, fechas, etc. Adem√°s, los √≠ndices no necesariamente tienen que estar en orden o ser consecutivos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------ SERIES a partir de LISTAS ESPECIFICANDO √çNDICE N√öMERICO ------ \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3    109\n",
       "4     78\n",
       "5      4\n",
       "6    189\n",
       "7     98\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------ SERIES a partir de LISTAS ESPECIFICANDO √çNDICE STRING ------ \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Lunes        109\n",
       "Martes        78\n",
       "Miercoles      4\n",
       "Jueves       189\n",
       "Viernes       98\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\" ------ SERIES a partir de LISTAS ESPECIFICANDO √çNDICE N√öMERICO ------ \")\n",
    "# vamos a definir una nueva serie pero en este caso vamos a ponerle nuestro propio √≠ndice usando el par√°metro 'index'\n",
    "serie_lista2 = pd.Series(lista, index = [3,4,5,6,7])\n",
    "display(serie_lista2)\n",
    "\n",
    "print(\" ------ SERIES a partir de LISTAS ESPECIFICANDO √çNDICE STRING ------ \")\n",
    "\n",
    "# como hemos mencionado los √≠ndices pueden ser de distintos tipos, en este caso crearemos una nueva Serie donde sus √≠ndices sean strings\n",
    "serie_lista3 = pd.Series(lista, index = [\"Lunes\",\"Martes\",\"Miercoles\",\"Jueves\",\"Viernes\"])\n",
    "display(serie_lista3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------ SERIES a partir de DICCIONARIOS ------ \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Manolo     20\n",
       "Lorena    220\n",
       "Paula     198\n",
       "Lola       78\n",
       "Marta     167\n",
       "Pablo      48\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\" ------ SERIES a partir de DICCIONARIOS ------ \")\n",
    "\n",
    "# definir un diccionario \n",
    "dicc = {'Manolo' : 20, \n",
    "        'Lorena' : 220, \n",
    "        'Paula' : 198, \n",
    "        'Lola': 78, \n",
    "       'Marta': 167, \n",
    "        'Pablo': 48} \n",
    "\n",
    "# crear una serie nueva a partir del diccionario definido previamente\n",
    "serie_diccionario = pd.Series(dicc)\n",
    "serie_diccionario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propiedades de las Series\n",
    "\n",
    "Las propiedades son atributos espec√≠ficos que nos proporcionan informaci√≥n sobre las caracter√≠sticas de una **Serie** en particular. Las propiedades m√°s importantes de las **Series** :\n",
    "\n",
    "1. `values`: Devuelve los valores de la **Serie** como un *array* NumPy. Podemos acceder a ellos utilizando la sintaxis `serie.values`.\n",
    "\n",
    "2. `index`: Devuelve los √≠ndices de la **Serie**. Como hemos dicho, los √≠ndices pueden ser de cualquier tipo, incluyendo *integer*s, *strings* u otros tipos o estructuras de datos. Podemos acceder a ellos utilizando la sintaxis `serie.index`.\n",
    "\n",
    "3. `dtype`: Devuelve el tipo de datos de los elementos en la Serie. Usaremos la sintaxis `serie.dtype`. Los tipos de datos m√°s comunes que podemos encontrar en una Serie son `int64`, `float64`, `object` (que es el *string* que conocemos de Python b√°sico), `datetime64`, entre otros.\n",
    "\n",
    "4. `size`: Devuelve el n√∫mero total de elementos en la Serie. Usaremos la sintaxis `serie.size`.\n",
    "\n",
    "5. `shape`: Devuelve una tupla que representa la forma (dimensiones) de la **Serie**. En el caso de una **Serie** unidimensional, la forma ser√° `(n,)`, donde `n` es el n√∫mero de elementos en la Serie. Usaremos la sintaxis `serie.shape`.\n",
    "\n",
    "Estas propiedades son √∫tiles para obtener informaci√≥n sobre una **Serie** en particular, como el tipo de datos, el n√∫mero de elementos y los √≠ndices asociados. Adem√°s, las propiedades pueden ser utilizadas en conjunto con los m√©todos y funciones de Pandas para realizar operaciones y an√°lisis m√°s avanzados en los datos de la **Serie**.\n",
    "\n",
    "Es importante tener en cuenta que las **Series** son inmutables, lo que significa que no podemos cambiar sus elementos directamente. Sin embargo, podremos realizar operaciones y manipulaciones para obtener nuevos resultados o modificar la estructura de los datos en funci√≥n de nuestras necesidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'La serie con la que vamos a trabajar es:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Manolo     20\n",
       "Lorena    220\n",
       "Paula     198\n",
       "Lola       78\n",
       "Marta     167\n",
       "Pablo      48\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "El m√©todo 'index' nos devuelve los √≠ndices de la Serie: Index(['Manolo', 'Lorena', 'Paula', 'Lola', 'Marta', 'Pablo'], dtype='object')\n",
      "---------------------------\n",
      "El m√©todo 'values' nos devuelve los valores de la Serie: [ 20 220 198  78 167  48]\n",
      "---------------------------\n",
      "El m√©todo 'shape' nos devuelve la forma de la Serie: (6,)\n",
      "---------------------------\n",
      "El m√©todo 'size' nos devuelve el n√∫mero de elementos de la Serie: 6\n",
      "---------------------------\n",
      "El m√©todo 'dtypes' nos devuelve el tipo de datos de la Serie: int64\n"
     ]
    }
   ],
   "source": [
    "# recordemos la serie\n",
    "display(\"La serie con la que vamos a trabajar es:\", serie_diccionario)\n",
    "print(\"---------------------------\")\n",
    "\n",
    "# utilizamos el m√©todo index que nos va a devolver todos los √≠ndices \n",
    "# fijaos como en este caso nos ha devuelto todos los √≠ndices de nuestra Serie, es decir, los nombres de las alumnas\n",
    "print(f\"El m√©todo 'index' nos devuelve los √≠ndices de la Serie: {serie_diccionario.index}\")\n",
    "print(\"---------------------------\")\n",
    "\n",
    "# ahora utilizamos el m√©todo 'values' nos devuelve todos los valores de la Serie\n",
    "# en este caso los n√∫meros que ten√≠amos\n",
    "print(f\"El m√©todo 'values' nos devuelve los valores de la Serie: {serie_diccionario.values}\")\n",
    "print(\"---------------------------\")\n",
    "\n",
    "#utilizando el m√©todo 'shape' nos devuelve el n√∫mero de \"filas\" que tenemos en la Serie\n",
    "print(f\"El m√©todo 'shape' nos devuelve la forma de la Serie: {serie_diccionario.shape}\")\n",
    "print(\"---------------------------\")\n",
    "\n",
    "#utilizando el m√©todo 'size' nos devuelve el n√∫mero de elementos que tenemos en la Serie\n",
    "print(f\"El m√©todo 'size' nos devuelve el n√∫mero de elementos de la Serie: {serie_diccionario.size}\")\n",
    "print(\"---------------------------\")\n",
    "\n",
    "#utilizando el m√©todo 'dtypes' nos devuelve el tipo de datos de la Serie\n",
    "print(f\"El m√©todo 'dtypes' nos devuelve el tipo de datos de la Serie: {serie_diccionario.dtypes}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexaci√≥n de las Series\n",
    "\n",
    "La indexaci√≥n se refiere a la forma en que accedemos a los elementos de una **Serie** utilizando √≠ndices o etiquetas. Pandas ofrece varias opciones para indexar y seleccionar elementos. Algunas de las principales formas de realizar la indexaci√≥n en las Series son:\n",
    "\n",
    "-  **Indexaci√≥n por posici√≥n**: Podemos acceder a los elementos de una **Serie** utilizando la posici√≥n num√©rica del elemento en la Serie, como hac√≠amos con las listas\n",
    "\n",
    "-  **Indexaci√≥n por etiqueta**: Podemos acceder a los elementos de una **Serie** utilizando las etiquetas de √≠ndice asociadas a cada elemento. \n",
    "\n",
    "-  **Indexaci√≥n por rango**: Podemos acceder a un rango de elementos de una **Serie** utilizando los √≠ndices de inicio y fin. \n",
    "\n",
    "- **Indexaci√≥n por lista de √≠ndices**: Podemos acceder a varios elementos de una **Serie** utilizando una lista de √≠ndices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ##### INDEXACI√ìN POR POSICI√ìN #####\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'La serie con la que vamos a trabajar es:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Manolo     20\n",
       "Lorena    220\n",
       "Paula     198\n",
       "Lola       78\n",
       "Marta     167\n",
       "Pablo      48\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "El valor que est√° en posici√≥n 0 es: 20\n",
      "---------------------------\n",
      "El valor que est√° en posici√≥n 2 es: 198\n"
     ]
    }
   ],
   "source": [
    "print(\" ##### INDEXACI√ìN POR POSICI√ìN #####\")\n",
    "display(\"La serie con la que vamos a trabajar es:\", serie_diccionario)\n",
    "print(\"---------------------------\")\n",
    "\n",
    "# accedemos al primer elemento (10). üö® Fijaos como los √≠ndices son como los de las listas, empiezan en 0\n",
    "print(\"El valor que est√° en posici√≥n 0 es:\", serie_diccionario[0])  \n",
    "print(\"---------------------------\")\n",
    "\n",
    "# accedemos al tercer elemento (30)\n",
    "print(\"El valor que est√° en posici√≥n 2 es:\", serie_diccionario[2])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ##### INDEXACI√ìN POR ETIQUETA #####\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'La serie con la que vamos a trabajar es:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Manolo     20\n",
       "Lorena    220\n",
       "Paula     198\n",
       "Lola       78\n",
       "Marta     167\n",
       "Pablo      48\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "El valor que est√° en posici√≥n 0 es: 78\n",
      "---------------------------\n",
      "El valor que est√° en posici√≥n 2 es: 48\n"
     ]
    }
   ],
   "source": [
    "print(\" ##### INDEXACI√ìN POR ETIQUETA #####\")\n",
    "display(\"La serie con la que vamos a trabajar es:\", serie_diccionario)\n",
    "print(\"---------------------------\")\n",
    "\n",
    "\n",
    "# accedemos al valor de la etiqueta de \"Lola\" (78). üö® Esto lo podr√≠amos comparar con los diccionarios\n",
    "print(\"El valor que est√° en posici√≥n 0 es:\", serie_diccionario[\"Lola\"])  \n",
    "print(\"---------------------------\")\n",
    "\n",
    "# accedemos al valor de la etiqueta de \"Pablo\" (48). \n",
    "print(\"El valor que est√° en posici√≥n 2 es:\", serie_diccionario[\"Pablo\"])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ##### INDEXACI√ìN POR RANGO #####\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'La serie con la que vamos a trabajar es:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Manolo     20\n",
       "Lorena    220\n",
       "Paula     198\n",
       "Lola       78\n",
       "Marta     167\n",
       "Pablo      48\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Los valores de los √≠ndices que est√°n entre las posiciones 1 y 3 (incluida) es: \n",
      " Lorena    220\n",
      "Paula     198\n",
      "Lola       78\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\" ##### INDEXACI√ìN POR RANGO #####\")\n",
    "display(\"La serie con la que vamos a trabajar es:\", serie_diccionario)\n",
    "print(\"---------------------------\")\n",
    "\n",
    "# accedemos a los elementos desde el √≠ndice 1 al 3 ([220, 198, 78]). üö® De niuevo fijaos como esto funciona igual que en listas\n",
    "# nos esta incluyendo el valor que est√° en el √≠ndice 1, pero no el que est√° en el √≠ndice 4\n",
    "print(\"Los valores de los √≠ndices que est√°n entre las posiciones 1 y 3 (incluida) es: \\n\", serie_diccionario[1:4])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ##### INDEXACI√ìN POR LISTA DE √çNDICES #####\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'La serie con la que vamos a trabajar es:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Manolo     20\n",
       "Lorena    220\n",
       "Paula     198\n",
       "Lola       78\n",
       "Marta     167\n",
       "Pablo      48\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Los valores de los √≠ndices que est√°n en las posiciones 1,3, y 4 son: \n",
      " Manolo     20\n",
      "Paula     198\n",
      "Lola       78\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\" ##### INDEXACI√ìN POR LISTA DE √çNDICES #####\")\n",
    "display(\"La serie con la que vamos a trabajar es:\", serie_diccionario)\n",
    "print(\"---------------------------\")\n",
    "\n",
    "# accedemos a los elementos con √≠ndices 1, 3 y 4. üö® Fijaos como en este caso, le hemos puesto dos corchetes\n",
    "print(\"Los valores de los √≠ndices que est√°n en las posiciones 1,3, y 4 son: \\n\", serie_diccionario[[0,2,3]])  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrames en Pandas\n",
    "\n",
    "## ¬øQu√© es un DataFrame?\n",
    "\n",
    "Un **DataFrame** es una estructura de datos bidimensional en forma de tabla, similar a una hoja de c√°lculo o una base de datos relacional. Es una de las estructuras de datos m√°s utilizadas en el an√°lisis de datos con Pandas.\n",
    "\n",
    "Las principales caracter√≠sticas de los **DataFrames** son:\n",
    "\n",
    "1. **Estructura tabular**: Est√°n organizados en filas y columnas. Cada columna representa una variable o caracter√≠stica, y cada fila representa una observaci√≥n o entrada de datos. Esto facilita la visualizaci√≥n y el manejo de los datos en forma tabular.\n",
    "\n",
    "2. **Flexibilidad**: Al contrario que las Series, los **DataFrames** pueden contener datos de diferentes tipos, como *integer*s, *float*s, *strings*, fechas, *bool*s, entre otros. Adem√°s, las columnas pueden tener nombres personalizados y los √≠ndices pueden ser etiquetados con valores personalizados.\n",
    "\n",
    "3. **Operaciones eficientes**: Los **DataFrames** est√°n dise√±ados para realizar operaciones eficientes en grandes conjuntos de datos. Ofrecen una amplia gama de funciones y m√©todos para manipular y analizar datos de manera r√°pida y eficiente.\n",
    "\n",
    "4. **Facilidad de importaci√≥n y exportaci√≥n**: Los **DataFrames** pueden leer y escribir datos en diversos formatos, como CSV, Excel, archivos de texto, bases de datos SQL, JSON, entre otros. Esto facilita la importaci√≥n y exportaci√≥n de datos desde y hacia diferentes fuentes de datos.\n",
    "\n",
    "5. **Indexaci√≥n flexible**: Los **DataFrames** permiten acceder y manipular los datos utilizando diversas t√©cnicas de indexaci√≥n, como indexaci√≥n por posici√≥n, indexaci√≥n por etiqueta, indexaci√≥n booleana y m√°s. Esto permite seleccionar y filtrar datos de manera precisa y eficiente.\n",
    "\n",
    "## Creaci√≥n de DataFrames\n",
    "\n",
    "En Pandas, podemos crear **DataFrames** a partir de una variedad de fuentes de datos. Las formas m√°s comunes para crear *DataFrames* son:\n",
    "\n",
    "1. **A partir de un diccionario de listas**: Podemos crear un **DataFrame** a partir de un diccionario de listas, donde cada clave representa una columna y cada valor es una lista representa los valores de esa columna. \n",
    "\n",
    "2. **A partir de una lista de diccionarios**: Podemos crear un **DataFrame** a partir de una lista de diccionarios, donde cada diccionario representa una fila y las claves del diccionario representan las columnas. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------ DATAFRAMES a partir de DICCIONARIO ------ \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nombre</th>\n",
       "      <th>Edad</th>\n",
       "      <th>Ciudad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lola</td>\n",
       "      <td>34</td>\n",
       "      <td>Londres</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Manolo</td>\n",
       "      <td>89</td>\n",
       "      <td>Madrid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pablo</td>\n",
       "      <td>12</td>\n",
       "      <td>Roma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mar√≠a</td>\n",
       "      <td>52</td>\n",
       "      <td>Paris</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Nombre  Edad   Ciudad\n",
       "0    Lola    34  Londres\n",
       "1  Manolo    89   Madrid\n",
       "2   Pablo    12     Roma\n",
       "3   Mar√≠a    52    Paris"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\" ------ DATAFRAMES a partir de DICCIONARIO ------ \")\n",
    "\n",
    "# definimos un diccionario que luego convertiremos a DataFrame. Recordemos que esta era la forma que utilizamos en las lecciones del m√≥dulo 2 de web scraping\n",
    "data_diccionario = {\n",
    "    'Nombre': ['Lola', 'Manolo', 'Pablo', 'Mar√≠a'],\n",
    "    'Edad': [34, 89, 12, 52],\n",
    "    'Ciudad': ['Londres', 'Madrid', 'Roma', 'Paris']\n",
    "}\n",
    "\n",
    "# convertimos el diccionario en DataFrame usando el m√©todo 'pd.DataFrame'\n",
    "df_diccionario = pd.DataFrame(data_diccionario)\n",
    "\n",
    "# mostramos el DataFrame. Recordad que para ver las 5 primeras filas usaremos el m√©todo '.head()' \n",
    "df_diccionario.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------ DATAFRAMES a partir de LISTA ------ \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nombre</th>\n",
       "      <th>Edad</th>\n",
       "      <th>Ciudad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sof√≠a</td>\n",
       "      <td>22</td>\n",
       "      <td>M√©xico DF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Luis</td>\n",
       "      <td>27</td>\n",
       "      <td>Guadalajara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Laura</td>\n",
       "      <td>33</td>\n",
       "      <td>Monterrey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Carlos</td>\n",
       "      <td>29</td>\n",
       "      <td>Puebla</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Nombre  Edad       Ciudad\n",
       "0   Sof√≠a    22    M√©xico DF\n",
       "1    Luis    27  Guadalajara\n",
       "2   Laura    33    Monterrey\n",
       "3  Carlos    29       Puebla"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\" ------ DATAFRAMES a partir de LISTA ------ \")\n",
    "\n",
    "# definimos una lista de diccionarios que luego usaremos para convertir en DataFrame\n",
    "data_lista = [\n",
    "    {'Nombre': 'Sof√≠a', 'Edad': 22, 'Ciudad': 'M√©xico DF'},\n",
    "    {'Nombre': 'Luis', 'Edad': 27, 'Ciudad': 'Guadalajara'},\n",
    "    {'Nombre': 'Laura', 'Edad': 33, 'Ciudad': 'Monterrey'},\n",
    "    {'Nombre': 'Carlos', 'Edad': 29, 'Ciudad': 'Puebla'}\n",
    "]\n",
    "\n",
    "\n",
    "# usamos el m√©todo 'pd.DataFrame' para convertir la lista de diccionarios a DataFrame\n",
    "df_lista = pd.DataFrame(data_lista)\n",
    "\n",
    "# mostramos el DataFrame, en este caso usaremos el m√©todo '.tail()' para mostrar las √∫ltimas 5 filas. \n",
    "df_lista.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura de archivos en Pandas\n",
    "\n",
    "En Pandas, disponemos de diversos m√©todos para abrir y leer diferentes tipos de archivos. Algunos de los m√©todos m√°s comunes utilizados para la lectura de archivos en Pandas:\n",
    "\n",
    "- `pd.read_csv`\n",
    "\n",
    "- `pd.read_excel`\n",
    "\n",
    "- `pd.read_json`\n",
    "\n",
    "- `pd.read_pickle`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pd.read_csv()`: \n",
    "\n",
    "Nos va a permitir leer archivos csv, su sintaxis b√°sica es: \n",
    "\n",
    "```python\n",
    "pd.read_csv(ruta_al_fichero , sep=',', delimiter=None, header='infer', names=None, index_col=None, dtype=None)\n",
    "```\n",
    "\n",
    "¬øQu√© significan todos estos par√°metros?\n",
    "\n",
    "- `ruta_al_fichero`: La direcci√≥n de tu archivo CSV que queremos leer.\n",
    "\n",
    "- `sep` (opcional): Para indicarle a Pandas c√≥mo est√°n separados los datos en nuestro archivo. Normalmente es una coma, pero si es algo diferente, aqu√≠ es donde deber√≠amos cambiarlo.\n",
    "\n",
    "- `delimiter` (opcional): Es lo mismo que `sep`, solo que con un nombre diferente. Puedes usar cualquiera de los dos.\n",
    "\n",
    "- `header` (opcional): Indicar√° la fila del archivo CSV que queremos que sea el encabezado del **DataFrame**. Puede tomar los siguientes valores:\n",
    "  \n",
    "  - `None`: No hay encabezado y los datos se leer√°n sin nombres de columna.\n",
    "  \n",
    "  - `'infer'`: Intentar√° inferir autom√°ticamente los nombres de columna del archivo, este es el que esta por defecto.\n",
    "\n",
    "  - Un n√∫mero *integer* que especifica la fila del archivo que se utilizar√° como encabezado de columna (por ejemplo, `header=0`).\n",
    " \n",
    "\n",
    "- `names` (opcional): Si quieres cambiar los nombres de las columnas por algo m√°s espec√≠fico. Debe ser una lista.Si se proporciona, reemplazar√° los nombres inferidos o los nombres de columna del archivo.\n",
    "\n",
    "  \n",
    "- `index_col` (opcional): Especifica la columna (o columnas) que se utilizar√°/n como √≠ndice del **DataFrame**. Puede ser un n√∫mero *integer*, una cadena con el nombre de la columna o una lista de columnas.\n",
    "\n",
    "- `dtype` (opcional): Esto es para especificar el tipo de datos de tus columnas. \n",
    "\n",
    "- `usecols` (opcional): Carga solo columnas especificadas, las columnas deben ser pasadas en formato lista. \n",
    "  \n",
    "  \n",
    "Estos son solo los conceptos b√°sicos, pero `pd.read_csv()` tiene un mont√≥n m√°s de trucos en la manga, como saltarse filas, manejar valores nulos y m√°s. Puedes echar un vistazo a la documentaci√≥n oficial [aqu√≠](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html) para descubrir m√°s sobre todas las cosas geniales que puedes hacer con esta funci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Datos/Pandas/aire.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_jobs \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../Datos/Pandas/aire.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m df_jobs\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Datos/Pandas/aire.csv'"
     ]
    }
   ],
   "source": [
    "df_jobs = pd.read_csv(\"../Datos/Pandas/aire.csv\")\n",
    "df_jobs.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como la propia definici√≥n indica, nuestras columnas deben ir separadas por comas. A veces, puede ocurrir que no vengan separados por comas. Como en el csv que acabamos de abrir. Y es que si nos fijamos nuestras columnas est√°n separadas por `;`. ¬øC√≥mo podemos solucionar esto? \n",
    "\n",
    "> Usando el par√°metro `sep` de `pd.read_csv` donde tendremos que especificar por qu√© est√°n separadas mis columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>provincia</th>\n",
       "      <th>municipio</th>\n",
       "      <th>estacion</th>\n",
       "      <th>magnitud</th>\n",
       "      <th>punto_muestreo</th>\n",
       "      <th>ano</th>\n",
       "      <th>mes</th>\n",
       "      <th>dia</th>\n",
       "      <th>h01</th>\n",
       "      <th>v01</th>\n",
       "      <th>h02</th>\n",
       "      <th>v02</th>\n",
       "      <th>h03</th>\n",
       "      <th>v03</th>\n",
       "      <th>h04</th>\n",
       "      <th>v04</th>\n",
       "      <th>h05</th>\n",
       "      <th>v05</th>\n",
       "      <th>h06</th>\n",
       "      <th>v06</th>\n",
       "      <th>h07</th>\n",
       "      <th>v07</th>\n",
       "      <th>h08</th>\n",
       "      <th>v08</th>\n",
       "      <th>h09</th>\n",
       "      <th>v09</th>\n",
       "      <th>h10</th>\n",
       "      <th>v10</th>\n",
       "      <th>h11</th>\n",
       "      <th>v11</th>\n",
       "      <th>h12</th>\n",
       "      <th>v12</th>\n",
       "      <th>h13</th>\n",
       "      <th>v13</th>\n",
       "      <th>h14</th>\n",
       "      <th>v14</th>\n",
       "      <th>h15</th>\n",
       "      <th>v15</th>\n",
       "      <th>h16</th>\n",
       "      <th>v16</th>\n",
       "      <th>h17</th>\n",
       "      <th>v17</th>\n",
       "      <th>h18</th>\n",
       "      <th>v18</th>\n",
       "      <th>h19</th>\n",
       "      <th>v19</th>\n",
       "      <th>h20</th>\n",
       "      <th>v20</th>\n",
       "      <th>h21</th>\n",
       "      <th>v21</th>\n",
       "      <th>h22</th>\n",
       "      <th>v22</th>\n",
       "      <th>h23</th>\n",
       "      <th>v23</th>\n",
       "      <th>h24</th>\n",
       "      <th>v24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28102001_1_38</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>3.0</td>\n",
       "      <td>T</td>\n",
       "      <td>3.0</td>\n",
       "      <td>T</td>\n",
       "      <td>3.0</td>\n",
       "      <td>T</td>\n",
       "      <td>3.0</td>\n",
       "      <td>T</td>\n",
       "      <td>3.0</td>\n",
       "      <td>T</td>\n",
       "      <td>3.0</td>\n",
       "      <td>T</td>\n",
       "      <td>3.0</td>\n",
       "      <td>T</td>\n",
       "      <td>3.0</td>\n",
       "      <td>T</td>\n",
       "      <td>3.0</td>\n",
       "      <td>T</td>\n",
       "      <td>3.0</td>\n",
       "      <td>T</td>\n",
       "      <td>3.0</td>\n",
       "      <td>T</td>\n",
       "      <td>3.0</td>\n",
       "      <td>T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   provincia  municipio  estacion  magnitud punto_muestreo   ano  mes  dia  \\\n",
       "0         28        102         1         1  28102001_1_38  2022    1   30   \n",
       "\n",
       "   h01 v01  h02 v02  h03 v03  h04 v04  h05 v05  h06 v06  h07 v07  h08 v08  \\\n",
       "0  3.0   T  3.0   T  3.0   T  3.0   T  3.0   T  3.0   T  3.0   T  3.0   T   \n",
       "\n",
       "   h09 v09  h10 v10  h11 v11  h12 v12  h13 v13  h14 v14  h15 v15  h16 v16  \\\n",
       "0  3.0   T  3.0   T  3.0   T  3.0   T  NaN   N  NaN   N  NaN   N  NaN   N   \n",
       "\n",
       "   h17 v17  h18 v18  h19 v19  h20 v20  h21 v21  h22 v22  h23 v23  h24 v24  \n",
       "0  NaN   N  NaN   N  NaN   N  NaN   N  NaN   N  NaN   N  NaN   N  NaN   N  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aire = pd.read_csv(\"../Datos/Pandas/aire.csv\", sep = \";\")\n",
    "df_aire.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pd.read_excel()`\n",
    "\n",
    "La sintaxis b√°sica de `pd.read_excel` es la siguiente:\n",
    "\n",
    "```python\n",
    "pd.read_excel(ruta_al_fichero, sheet_name=0, header=0, names=None, index_col=None, dtype=None)\n",
    "```\n",
    "\n",
    "Donde:\n",
    "- `ruta_al_fichero`:  Es el nombre del archivo o la ruta de Excel que queremos leer. \n",
    "\n",
    "- `sheet_name` (opcional): Indica la hoja o hojas del archivo Excel que queremos leer. Puede tener los siguientes valores:\n",
    "\n",
    "  - Un n√∫mero *integer* que especifica el √≠ndice de la hoja (por ejemplo, `sheet_name=0` para la primera hoja).\n",
    "\n",
    "  - Un nombre de hoja como una cadena (por ejemplo, `sheet_name='Sheet1'`).\n",
    "\n",
    "  - Una lista de nombres de hojas para leer varias hojas (por ejemplo, `sheet_name=['Sheet1', 'Sheet2']`).\n",
    "\n",
    "- `header` (opcional): Indica la fila del archivo Excel que se utilizar√° como encabezado de columnas. Puede tener los siguientes valores:\n",
    "\n",
    "  - `None`: No hay encabezado y los datos se leer√°n sin nombres de columna.\n",
    "\n",
    "  - Un n√∫mero *integer* que especifica la fila del archivo que se utilizar√° como encabezado de columna (por ejemplo, `header=0`).\n",
    "\n",
    "- `names` (opcional): Es una lista opcional de nombres para las columnas. Si se proporciona, reemplazar√° los nombres inferidos o los nombres de columna del archivo.\n",
    "\n",
    "- `index_col` (opcional): Especifica la columna (o columnas) que se utilizar√° como √≠ndice del DataFrame resultante. Puede ser un n√∫mero *integer*, una cadena con el nombre de la columna o una lista de columnas.\n",
    "\n",
    "- `dtype` (opcional): Permite especificar el tipo de datos de las columnas. Puede ser un diccionario que mapee nombres de columna a tipos de datos o un solo tipo de datos para aplicar a todas las columnas.\n",
    "\n",
    "Adem√°s de estos par√°metros, `pd.read_excel` tambi√©n admite otros par√°metros opcionales, como `skiprows`, `na_values`, `usecols` y m√°s. Estos par√°metros nos permiten personalizar a√∫n m√°s la lectura de archivos Excel seg√∫n tus necesidades. Al igual que en el m√©todo `pd.read_csv()`, podemos  consultar la [documentaci√≥n oficial](https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html) para obtener informaci√≥n m√°s detallada sobre estos par√°metros y sus opciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Datos/Pandas/espacios_protegidos.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_xlsx \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../Datos/Pandas/espacios_protegidos.xlsx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m df_xlsx\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\excel\\_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    494\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 495\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\excel\\_base.py:1550\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   1548\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1549\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1550\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m   1552\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1554\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1555\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1556\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1557\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\excel\\_base.py:1402\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1400\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[1;32m-> 1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1404\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m   1405\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   1406\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Datos/Pandas/espacios_protegidos.xlsx'"
     ]
    }
   ],
   "source": [
    "df_xlsx = pd.read_excel(\"../Datos/Pandas/espacios_protegidos.xlsx\", sheet_name=0)\n",
    "df_xlsx.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üö®‚ö†Ô∏è **NOTA** Puede que al ejecutar este l√≠nea de c√≥digo os salga el siguiente error: \n",
    "\n",
    "![error](imagenes/error_excel.png)\n",
    "\n",
    "**DON'T PANIC!!!** Lo √∫nico que tendremos que hacer es importaros `openpyxl`. ¬øC√≥mo? Nos vamos a la terminal y ejecutamos el siguiente c√≥digo: \n",
    "\n",
    "```bash \n",
    "pip3 install openpyxl\n",
    "\n",
    "pip install openpyxl\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>espacio_prot_categoria</th>\n",
       "      <th>espacio_prot_figura</th>\n",
       "      <th>espacio_prot_nombre</th>\n",
       "      <th>espacio_prot_superficie_ha</th>\n",
       "      <th>espacio_prot_fecha_declaracion</th>\n",
       "      <th>espacio_prot_normativa</th>\n",
       "      <th>espacio_prot_informacion_web</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>√Åreas protegidas por instrumentos internacionales</td>\n",
       "      <td>Reserva de la Biosfera</td>\n",
       "      <td>Cuencas Altas de los r√≠os Manzanares, Lozoya y...</td>\n",
       "      <td>105655.000</td>\n",
       "      <td>1992-11-09</td>\n",
       "      <td>Normativa √Åreas protegidas por instrumentos in...</td>\n",
       "      <td>Reserva de la Biosfera Cuencas Altas de los r√≠...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>√Åreas protegidas por instrumentos internacionales</td>\n",
       "      <td>Reserva de la Biosfera</td>\n",
       "      <td>Sierra del Rinc√≥n</td>\n",
       "      <td>15231.000</td>\n",
       "      <td>2005-06-29</td>\n",
       "      <td>Normativa √Åreas protegidas por instrumentos in...</td>\n",
       "      <td>Reserva de la Biosfera Sierra del Rinc√≥n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>√Åreas protegidas por instrumentos internacionales</td>\n",
       "      <td>Humedal de Importancia Internacional (RAMSAR)</td>\n",
       "      <td>Humedales del Macizo de Pe√±alara</td>\n",
       "      <td>487.198</td>\n",
       "      <td>2005-12-16</td>\n",
       "      <td>Normativa √Åreas protegidas por instrumentos in...</td>\n",
       "      <td>Humedales Ramsar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Espacios Protegidos Red Natura 2000</td>\n",
       "      <td>Zona de Especial Protecci√≥n para las Aves</td>\n",
       "      <td>Monte de El Pardo</td>\n",
       "      <td>15298.670</td>\n",
       "      <td>1988-02-01</td>\n",
       "      <td>Normativa Espacios Protegidos Red Natura 2000</td>\n",
       "      <td>Espacios protegidos Red Natura 2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Espacios Protegidos Red Natura 2000</td>\n",
       "      <td>Zona de Especial Protecci√≥n para las Aves</td>\n",
       "      <td>Soto de Vi√±uelas</td>\n",
       "      <td>3071.890</td>\n",
       "      <td>1988-02-01</td>\n",
       "      <td>Normativa Espacios Protegidos Red Natura 2000</td>\n",
       "      <td>Espacios protegidos Red Natura 2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              espacio_prot_categoria  \\\n",
       "0  √Åreas protegidas por instrumentos internacionales   \n",
       "1  √Åreas protegidas por instrumentos internacionales   \n",
       "2  √Åreas protegidas por instrumentos internacionales   \n",
       "3                Espacios Protegidos Red Natura 2000   \n",
       "4                Espacios Protegidos Red Natura 2000   \n",
       "\n",
       "                             espacio_prot_figura  \\\n",
       "0                         Reserva de la Biosfera   \n",
       "1                         Reserva de la Biosfera   \n",
       "2  Humedal de Importancia Internacional (RAMSAR)   \n",
       "3      Zona de Especial Protecci√≥n para las Aves   \n",
       "4      Zona de Especial Protecci√≥n para las Aves   \n",
       "\n",
       "                                 espacio_prot_nombre  \\\n",
       "0  Cuencas Altas de los r√≠os Manzanares, Lozoya y...   \n",
       "1                                  Sierra del Rinc√≥n   \n",
       "2                  Humedales del Macizo de Pe√±alara    \n",
       "3                                  Monte de El Pardo   \n",
       "4                                   Soto de Vi√±uelas   \n",
       "\n",
       "   espacio_prot_superficie_ha espacio_prot_fecha_declaracion  \\\n",
       "0                  105655.000                     1992-11-09   \n",
       "1                   15231.000                     2005-06-29   \n",
       "2                     487.198                     2005-12-16   \n",
       "3                   15298.670                     1988-02-01   \n",
       "4                    3071.890                     1988-02-01   \n",
       "\n",
       "                              espacio_prot_normativa  \\\n",
       "0  Normativa √Åreas protegidas por instrumentos in...   \n",
       "1  Normativa √Åreas protegidas por instrumentos in...   \n",
       "2  Normativa √Åreas protegidas por instrumentos in...   \n",
       "3      Normativa Espacios Protegidos Red Natura 2000   \n",
       "4      Normativa Espacios Protegidos Red Natura 2000   \n",
       "\n",
       "                        espacio_prot_informacion_web  \n",
       "0  Reserva de la Biosfera Cuencas Altas de los r√≠...  \n",
       "1           Reserva de la Biosfera Sierra del Rinc√≥n  \n",
       "2                                   Humedales Ramsar  \n",
       "3                Espacios protegidos Red Natura 2000  \n",
       "4                Espacios protegidos Red Natura 2000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# volvemos a ejecutar el c√≥digo para abrir el fichero\n",
    "df_xlsx = pd.read_excel(\"../Datos/Pandas/espacios_protegidos.xlsx\", sheet_name=0)\n",
    "df_xlsx.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pd.read_json()`\n",
    "\n",
    "Nos va a permitir abrir arcivos de tipo json. La sintaxis b√°sica de `pd.read_json` es la siguiente:\n",
    "\n",
    "```python\n",
    "pd.read_json(ruta_al_fichero, orient=None, typ='frame', dtype=True, convert_axes=True, convert_dates=True, keep_default_dates=True, numpy=False, precise_float=False, date_unit=None, encoding=None, lines=False)\n",
    "```\n",
    "\n",
    "Los par√°metros que puede recibir este m√©todo son:\n",
    "\n",
    "- `ruta_al_fichero`: Es la ruta del archivo JSON que deseamos leer.\n",
    "\n",
    "- `orient` (opcional): Especifica la orientaci√≥n del archivo JSON. Puede tener los siguientes valores:\n",
    "\n",
    "  - `'columns'` (por defecto): Se espera que el archivo JSON tenga un formato de columna.\n",
    "\n",
    "  - `'index'`: Se espera que el archivo JSON tenga un formato de √≠ndice.\n",
    "\n",
    "  - `'records'`: Se espera que el archivo JSON tenga un formato de registros.\n",
    "\n",
    "  - `'split'`: Se espera que el archivo JSON tenga un formato dividido.\n",
    "\n",
    "  - `'values'`: Se espera que el archivo JSON contenga solo valores sin ninguna etiqueta de columna o √≠ndice.\n",
    "\n",
    "- `typ` (opcional): Indica el tipo de objeto a crear. Puede tener los siguientes valores:\n",
    "\n",
    "  - `'frame'` (por defecto): Crea un objeto DataFrame.\n",
    "\n",
    "  - `'series'`: Crea un objeto Series.\n",
    "\n",
    "- `dtype` (opcional): Permite especificar el tipo de datos de las columnas. Puede ser un diccionario que mapee nombres de columna a tipos de datos o un solo tipo de datos para aplicar a todas las columnas.\n",
    "\n",
    "- `convert_axes` (opcional): Indica si las etiquetas de los ejes deben convertirse en √≠ndices o nombres de columna. Por defecto, es `True`.\n",
    "\n",
    "- `convert_dates` (opcional): Indica si se deben convertir las cadenas de fecha y hora en objetos de fecha y hora. Por defecto, es `True`.\n",
    "\n",
    "- `keep_default_dates` (opcional): Especifica si se deben mantener las fechas predeterminadas al convertir cadenas de fecha y hora. Por defecto, es `True`.\n",
    "\n",
    "- `numpy` (opcional): Indica si los datos deben devolverse como una matriz NumPy en lugar de un objeto DataFrame. Por defecto, es `False`.\n",
    "\n",
    "- `precise_float` (opcional): Indica si se deben utilizar n√∫meros de punto *float* precisos en lugar de valores de punto *float* nativos de Python. Por defecto, es `False`.\n",
    "\n",
    "- `date_unit` (opcional): Especifica la unidad de fecha y hora si se deben convertir las cadenas de fecha y hora. Puede ser `'s'` para segundos o `'ms'` para milisegundos.\n",
    "\n",
    "- `encoding` (opcional): Permite especificar la codificaci√≥n del archivo JSON si no se puede inferir autom√°ticamente.\n",
    "\n",
    "- `lines` (opcional): Indica si el archivo JSON contiene m√∫ltiples objetos JSON en l√≠neas separadas en lugar de un solo objeto JSON.\n",
    "\n",
    "Estos son solo algunos de los par√°metros m√°s comunes utilizados en `pd.read_json`. La funci√≥n `pd.read_json` tambi√©n admite otros par√°metros opcionales, como `orient`, `date_format`, `numpy`, `compression` y m√°s. Podemos consultar la [documentaci√≥n oficial](https://pandas.pydata.org/docs/reference/api/pandas.read_json.html) para obtener informaci√≥n m√°s detallada sobre estos par√°metros y sus opciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'residuos_pelig_cantidad_ton': 23476.42, 'res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'residuos_pelig_cantidad_ton': 1927.25, 'resi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'residuos_pelig_cantidad_ton': 25333.54, 'res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'residuos_pelig_cantidad_ton': 22060.07, 'res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'residuos_pelig_cantidad_ton': 13109.74, 'res...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data\n",
       "0  {'residuos_pelig_cantidad_ton': 23476.42, 'res...\n",
       "1  {'residuos_pelig_cantidad_ton': 1927.25, 'resi...\n",
       "2  {'residuos_pelig_cantidad_ton': 25333.54, 'res...\n",
       "3  {'residuos_pelig_cantidad_ton': 22060.07, 'res...\n",
       "4  {'residuos_pelig_cantidad_ton': 13109.74, 'res..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_residuos = pd.read_json(\"../Datos/Pandas/residuos.json\")\n",
    "df_residuos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>residuos_pelig_cantidad_ton</th>\n",
       "      <th>residuos_pelig_a√±o</th>\n",
       "      <th>residuos_pelig_opcion_gestion</th>\n",
       "      <th>residuos_pelig_tratamiento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23476.42</td>\n",
       "      <td>2012</td>\n",
       "      <td>Reciclado</td>\n",
       "      <td>Recuperaci√≥n de disolventes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1927.25</td>\n",
       "      <td>2012</td>\n",
       "      <td>Reciclado</td>\n",
       "      <td>Recuperaci√≥n de metales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25333.54</td>\n",
       "      <td>2012</td>\n",
       "      <td>Reciclado</td>\n",
       "      <td>Regeneraci√≥n de aceite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22060.07</td>\n",
       "      <td>2012</td>\n",
       "      <td>Tratamiento previo a otras formas de valorizaci√≥n</td>\n",
       "      <td>Trituraci√≥n previa a valorizaci√≥n de bater√≠as</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13109.74</td>\n",
       "      <td>2012</td>\n",
       "      <td>Tratamiento previo a otras formas de valorizaci√≥n</td>\n",
       "      <td>Operaciones previas a valorizaci√≥n de RAEE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   residuos_pelig_cantidad_ton  residuos_pelig_a√±o  \\\n",
       "0                     23476.42                2012   \n",
       "1                      1927.25                2012   \n",
       "2                     25333.54                2012   \n",
       "3                     22060.07                2012   \n",
       "4                     13109.74                2012   \n",
       "\n",
       "                       residuos_pelig_opcion_gestion  \\\n",
       "0                                          Reciclado   \n",
       "1                                          Reciclado   \n",
       "2                                          Reciclado   \n",
       "3  Tratamiento previo a otras formas de valorizaci√≥n   \n",
       "4  Tratamiento previo a otras formas de valorizaci√≥n   \n",
       "\n",
       "                      residuos_pelig_tratamiento  \n",
       "0                    Recuperaci√≥n de disolventes  \n",
       "1                        Recuperaci√≥n de metales  \n",
       "2                         Regeneraci√≥n de aceite  \n",
       "3  Trituraci√≥n previa a valorizaci√≥n de bater√≠as  \n",
       "4     Operaciones previas a valorizaci√≥n de RAEE  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# esto nos devuelve un DataFrame que esta lleno de diccionarios!\n",
    "# sin embargo, lo podemos convertir f√°cilmente a algo m√°s legible usando la siguiente sintaxis\n",
    "\n",
    "df_residuos2 = df_residuos['data'].apply(pd.Series)\n",
    "df_residuos2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pd.read_pickle`\n",
    "\n",
    "\n",
    "**¬øQu√© es Pickle exactamente?**\n",
    "\n",
    "Un archivo de tipo pickle es un archivo binario en Python que se utiliza para serializar y deserializar objetos,  su acr√≥nimo viene de *Python Pickle Format* que fue desarrollado exclusivamente para Python. Leyendo solo esto podemos seguir sin tener claro que es un archivo de tipo pickle. Expliquemoslo de una forma m√°s sencilla. Imagina que tienes un mont√≥n de objetos especiales en tu habitaci√≥n, como juguetes, libros, peluches, etc. Ahora, supongamos que quieres guardar todos estos objetos en una caja para poder llevarlos contigo o almacenarlos de manera segura.\n",
    "\n",
    "Aqu√≠ es donde entra en juego un archivo pickle. Es como una caja especial que te permite guardar todos estos objetos en ella. Pero, en lugar de objetos f√≠sicos, el archivo pickle puede almacenar objetos digitales, como datos, n√∫meros, listas, diccionarios y m√°s.\n",
    "\n",
    "El archivo pickle es como una caja m√°gica que puede guardar todos tus objetos digitales de Python. Cuando guardas estos objetos en un archivo pickle, se convierten en una forma especial que se puede almacenar en tu computadora o enviar a alguien m√°s.\n",
    "\n",
    "La sintaxis b√°sica de `pd.read_pickle` es la siguiente:\n",
    "\n",
    "```python\n",
    "pd.read_pickle(ruta_al_fichero, compression='infer')\n",
    "```\n",
    "\n",
    "Donde:\n",
    "\n",
    "- `filepath_or_buffer`: Es la ruta del archivo pickle que deseas leer.\n",
    "\n",
    "- `compression` (opcional): Es un par√°metro opcional que indica el tipo de compresi√≥n utilizado en el archivo pickle. Por defecto, es `'infer'`, lo que significa que la biblioteca intentar√° inferir autom√°ticamente el tipo de compresi√≥n. Puedes especificar un tipo de compresi√≥n expl√≠citamente, como `'gzip'` o `'bz2'`, si el archivo pickle est√° comprimido.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Colombia': 'Bogot√°', 'Ecuador': 'Quito', 'Argentina': 'Buenos'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pkl = pd.read_pickle(\"../Datos/Pandas/paises_capitales.pkl\")\n",
    "df_pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexaci√≥n en Pandas (`loc` e `iloc`)\n",
    "\n",
    "En Pandas, tanto `loc` como `iloc` son m√©todos para acceder y manipular datos en un **DataFrame**. Ambos m√©todos ofrecen formas de indexar datos, ya sea utilizando etiquetas o n√∫meros, respectivamente.\n",
    "\n",
    "- `loc`: Este m√©todo se utiliza para acceder a los datos utilizando etiquetas de fila y columna. Con `loc`, podemos seleccionar filas y columnas **utilizando sus nombres o etiquetas**. La sintaxis general para `loc` es `df.loc[nombre_filas, nombre_columnas]`, donde `filas` y `columnas` pueden ser un √∫nico nombre o una lista de nombres.\n",
    "\n",
    "- `iloc`: Se utiliza para acceder a los datos utilizando √≠ndices de filas y columnas. Con `iloc`, podemos seleccionar filas y columnas **bas√°ndonos en sus posiciones num√©ricas**. La sintaxis general para `iloc` es `df.iloc[√≠ndice_filas, √≠ndice_columnas]`, donde `filas` y `columnas` pueden ser un √∫nico n√∫mero(√≠ndice) o una lista de n√∫meros(√≠ndices).\n",
    "\n",
    "La principal diferencia entre `loc` y `iloc` radica en c√≥mo se realizan las selecciones:\n",
    "\n",
    "- `loc`: Utiliza etiquetas o nombres de filas y columnas para indexar los datos. Por ejemplo, `df.loc[3, 'A']` seleccionar√° el valor en la fila con etiqueta 3 y la columna con etiqueta 'A'.\n",
    "\n",
    "- `iloc`: Por otro lado, `iloc` utiliza √≠ndices basados en la posici√≥n para realizar las selecciones. Por ejemplo, `df.iloc[3, 0]` seleccionar√° el valor en la cuarta fila y primera columna (recordemos que los √≠ndices empiezan en 0).\n",
    "\n",
    "Adem√°s, debemos tener en cuenta que `loc` incluye el l√≠mite superior en los rangos de selecci√≥n, mientras que `iloc` lo excluye. Por ejemplo, `df.loc[1:3, 'A']` seleccionar√° las filas con etiquetas 1, 2 y 3, mientras que `df.iloc[1:3, 0]` seleccionar√° las filas con √≠ndices 1 y 2 (excluyendo el √≠ndice 3).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Oro</th>\n",
       "      <th>Plata</th>\n",
       "      <th>Bronce</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pa√≠s</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>China</th>\n",
       "      <td>1473</td>\n",
       "      <td>994</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jap√≥n</th>\n",
       "      <td>1032</td>\n",
       "      <td>1037</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corea del Sur</th>\n",
       "      <td>745</td>\n",
       "      <td>663</td>\n",
       "      <td>827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ir√°n</th>\n",
       "      <td>179</td>\n",
       "      <td>181</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kazajist√°n</th>\n",
       "      <td>155</td>\n",
       "      <td>158</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>India</th>\n",
       "      <td>154</td>\n",
       "      <td>202</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tailandia</th>\n",
       "      <td>132</td>\n",
       "      <td>175</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indonesia</th>\n",
       "      <td>112</td>\n",
       "      <td>131</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>China Taip√©i</th>\n",
       "      <td>99</td>\n",
       "      <td>144</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corea del Norte</th>\n",
       "      <td>91</td>\n",
       "      <td>120</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Oro  Plata  Bronce\n",
       "Pa√≠s                                \n",
       "China            1473    994     720\n",
       "Jap√≥n            1032   1037     985\n",
       "Corea del Sur     745    663     827\n",
       "Ir√°n              179    181     197\n",
       "Kazajist√°n        155    158     224\n",
       "India             154    202     315\n",
       "Tailandia         132    175     278\n",
       "Indonesia         112    131     240\n",
       "China Taip√©i       99    144     276\n",
       "Corea del Norte    91    120     235"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importamos un nuevo fichero de datos para entender mejor estos conceptos\n",
    "df = pd.read_csv(\"../Datos/Pandas/medallas.csv\",index_col=[\"Pa√≠s\"],  usecols=[\"Oro\",\"Plata\", \"Bronce\", \"Pa√≠s\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecci√≥n a trav√©s de un √∫nico elemento\n",
    "\n",
    "Vamos a intentar sacar el valor de 1037, en concreto hace referencia a las medallas de Plata de Jap√≥n. Recordemos que: \n",
    "\n",
    "- En el `loc` usaremos los nombres de las filas y las columnas (es como el juego de hundir la flota), corresponde a lo que tenemos en rojo en la imagen. \n",
    "\n",
    "- En el `iloc` usaremos los indices de las filas y las columnas, igual que hac√≠amos en las listas o los **array*s* de NumPy, corresponde con lo que vemos en verde en la imagen. \n",
    "\n",
    "![imagen](https://github.com/Hack-io-Data/Imagenes/blob/main/02-Imagenes/Pandas/dataframe_medallas_plata_japon.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El n√∫mero de medallas de Plata conseguidas por Jap√≥n usando el LOC son:  1037\n",
      "El n√∫mero de medallas de Plata conseguidas por Jap√≥n usando el ILOC es:  1037\n"
     ]
    }
   ],
   "source": [
    "# Usando el loc, accediendo por los nombres de las filas y las columnas\n",
    "print(f'El n√∫mero de medallas de Plata conseguidas por Jap√≥n usando el LOC son:  {df.loc[\"Jap√≥n\", \"Plata\"]}')\n",
    "\n",
    "# usando el iloc, accediendo por los √≠ndices, que empiezan en 0 como siempre en Python\n",
    "print(f'El n√∫mero de medallas de Plata conseguidas por Jap√≥n usando el ILOC es:  {df.iloc[1, 1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imaginemos que queremos sacar una fila en concreto pero todas las columnas o viceversa:\n",
    "\n",
    "> En estos casos tendremos que usar `:`, esto √≠ndica que lo queremos todo. Es decir: \n",
    "\n",
    "```python\n",
    "[filas_deseadas, :] # le estamos diciendo que nos busque por una fila dada y nos devuelva todas las columnas\n",
    "\n",
    "[:, columna_deseada] # devuelvenos todas las filas de la columna que especifiquemos\n",
    "```\n",
    "\n",
    "Imaginemos ahora que queremos extraer toda la informaci√≥n de Jap√≥n. En este caso, querremos de una fila concreta y todas las columnas. \n",
    "\n",
    "![imagen2](https://github.com/Hack-io-Data/Imagenes/blob/main/02-Imagenes/Pandas/dataframe_medallas_plata_japon.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El n√∫mero de medallas conseguidas por Jap√≥n  usando el LOC es: \n",
      "  Oro       1032\n",
      "Plata     1037\n",
      "Bronce     985\n",
      "Name: Jap√≥n, dtype: int64\n",
      "\n",
      "----------------------\n",
      "\n",
      "El n√∫mero de medallas conseguidas por Jap√≥n usando el ILOC es: \n",
      "  Oro       1032\n",
      "Plata     1037\n",
      "Bronce     985\n",
      "Name: Jap√≥n, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Usando el loc, accediendo por los nombres de las filas y las columnas\n",
    "print(f'El n√∫mero de medallas conseguidas por Jap√≥n  usando el LOC es: \\n  {df.loc[\"Jap√≥n\", :]}')\n",
    "\n",
    "print(\"\\n----------------------\\n\")\n",
    "# Usando el iloc, accediendo por los √≠ndices\n",
    "print(f'El n√∫mero de medallas conseguidas por Jap√≥n usando el ILOC es: \\n  {df.iloc[1, :]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¬øY si ahora quisieramos extraer todas las medallas de Oro para todos los pa√≠ses? En este caso querr√≠amos todas las filas y una sola columna. \n",
    "\n",
    "![imagen3](https://github.com/Hack-io-Data/Imagenes/blob/main/02-Imagenes/Pandas/dataframe_medallas_oro.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El n√∫mero de medalas de Oro de todos los pa√≠ses usando el LOC es: \n",
      "  Pa√≠s\n",
      "China              1473\n",
      "Jap√≥n              1032\n",
      "Corea del Sur       745\n",
      "Ir√°n                179\n",
      "Kazajist√°n          155\n",
      "India               154\n",
      "Tailandia           132\n",
      "Indonesia           112\n",
      "China Taip√©i         99\n",
      "Corea del Norte      91\n",
      "Name: Oro, dtype: int64\n",
      "\n",
      "----------------------\n",
      "\n",
      "El n√∫mero de medalas de Oro de todos los pa√≠ses usando el ILOC es: \n",
      "  Pa√≠s\n",
      "China              1473\n",
      "Jap√≥n              1032\n",
      "Corea del Sur       745\n",
      "Ir√°n                179\n",
      "Kazajist√°n          155\n",
      "India               154\n",
      "Tailandia           132\n",
      "Indonesia           112\n",
      "China Taip√©i         99\n",
      "Corea del Norte      91\n",
      "Name: Oro, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Usando el loc, accediendo por los nombres de las filas y las columnas\n",
    "print(f'El n√∫mero de medalas de Oro de todos los pa√≠ses usando el LOC es: \\n  {df.loc[:, \"Oro\"]}')\n",
    "\n",
    "print(\"\\n----------------------\\n\")\n",
    "# Usando el iloc, accediendo por los √≠ndices\n",
    "print(f'El n√∫mero de medalas de Oro de todos los pa√≠ses usando el ILOC es: \\n  {df.iloc[:, 0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecci√≥n a trav√©s de una lista de valores \n",
    "\n",
    "En este caso la sintaxis del `loc` y el `iloc` cambian un poco. Seguiremos usando los nombres de las filas y las columnas para el `loc` y los √≠ndices para el `iloc`, pero tendremos que a√±adir un corchete m√°s. \n",
    "\n",
    "```python\n",
    "[[fila_deseada1, fila_deseada2], :] # le estamos diciendo que nos busque por una fila dada y nos devuelva todas las columnas. FIJAOS COMO LO QUE HEMOS HECHO HA SIDO A√ëADIR UNOS CORCHETES M√ÅS DONDE INCLUIREMOS LOS NOMBRES DE LAS FILAS O COLUMNAS QUE QUERRAMOS SEPARADAS POR COMAS. Los ':' siguen indicando que queremo todas las columnas en este caso.\n",
    "\n",
    "[:, [col_deseada1, col_deseada2]] # devuelvenos todas las filas de la columna que especifiquemos. FIJAOS COMO LO QUE HEMOS HECHO HA SIDO A√ëADIR UNOS CORCHETES M√ÅS DONDE INCLUIREMOS LOS NOMBRES DE LAS FILAS O COLUMNAS QUE QUERRAMOS SEPARADAS POR COMAS. Los ':' siguen indicando que queremos todas las filas.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a querer extraer la informaci√≥n de las medallas de Oro, pero solo vamos a querer los datos de Corea (Corea del Sur y Corea del Norte). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Oro</th>\n",
       "      <th>Plata</th>\n",
       "      <th>Bronce</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pa√≠s</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>China</th>\n",
       "      <td>1473</td>\n",
       "      <td>994</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jap√≥n</th>\n",
       "      <td>1032</td>\n",
       "      <td>1037</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corea del Sur</th>\n",
       "      <td>745</td>\n",
       "      <td>663</td>\n",
       "      <td>827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ir√°n</th>\n",
       "      <td>179</td>\n",
       "      <td>181</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kazajist√°n</th>\n",
       "      <td>155</td>\n",
       "      <td>158</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>India</th>\n",
       "      <td>154</td>\n",
       "      <td>202</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tailandia</th>\n",
       "      <td>132</td>\n",
       "      <td>175</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indonesia</th>\n",
       "      <td>112</td>\n",
       "      <td>131</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>China Taip√©i</th>\n",
       "      <td>99</td>\n",
       "      <td>144</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corea del Norte</th>\n",
       "      <td>91</td>\n",
       "      <td>120</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Oro  Plata  Bronce\n",
       "Pa√≠s                                \n",
       "China            1473    994     720\n",
       "Jap√≥n            1032   1037     985\n",
       "Corea del Sur     745    663     827\n",
       "Ir√°n              179    181     197\n",
       "Kazajist√°n        155    158     224\n",
       "India             154    202     315\n",
       "Tailandia         132    175     278\n",
       "Indonesia         112    131     240\n",
       "China Taip√©i       99    144     276\n",
       "Corea del Norte    91    120     235"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las medallas de Oro para Corea del Norte y del Sur usando el LOC es: \n",
      "  Pa√≠s\n",
      "Corea del Sur      745\n",
      "Corea del Norte     91\n",
      "Name: Oro, dtype: int64\n",
      "\n",
      "----------------------\n",
      "\n",
      "Las medallas de Oro para Corea del Norte y del Sur usando el ILOC es: \n",
      "  Pa√≠s\n",
      "Corea del Sur      745\n",
      "Corea del Norte     91\n",
      "Name: Oro, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Usando el loc, accediendo por los nombres de las filas y las columnas\n",
    "print(f'Las medallas de Oro para Corea del Norte y del Sur usando el LOC es: \\n  {df.loc[[\"Corea del Sur\", \"Corea del Norte\"], \"Oro\"]}')\n",
    "\n",
    "print(\"\\n----------------------\\n\")\n",
    "# Usando el iloc, accediendo por los √≠ndices\n",
    "print(f'Las medallas de Oro para Corea del Norte y del Sur usando el ILOC es: \\n  {df.iloc[[2, -1], 0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imaginemos ahora que no queremos solo la informaci√≥n de las medallas de Oro para Corea del Norte y del Sur, si no que tambi√©n queremos la informaci√≥n de las medallas de Plata. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las medallas de Oro y Plata para Corea del Norte y del Sur usando el LOC es: \n",
      "                   Oro  Plata\n",
      "Pa√≠s                       \n",
      "Corea del Sur    745    663\n",
      "Corea del Norte   91    120\n",
      "\n",
      "----------------------\n",
      "\n",
      "Las medallas de Oro y Plata para Corea del Norte y del Sur usando el ILOC es: \n",
      "                   Oro  Plata\n",
      "Pa√≠s                       \n",
      "Corea del Sur    745    663\n",
      "Corea del Norte   91    120\n"
     ]
    }
   ],
   "source": [
    "# Usando el loc, accediendo por los nombres de las filas y las columnas\n",
    "print(f'Las medallas de Oro y Plata para Corea del Norte y del Sur usando el LOC es: \\n  {df.loc[[\"Corea del Sur\", \"Corea del Norte\"], [\"Oro\", \"Plata\"]]}')\n",
    "\n",
    "print(\"\\n----------------------\\n\")\n",
    "# Usando el iloc, accediendo por los √≠ndices\n",
    "print(f'Las medallas de Oro y Plata para Corea del Norte y del Sur usando el ILOC es: \\n  {df.iloc[[2, -1], [0,1]]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecci√≥n de un rango de datos a trav√©s de un corte\n",
    "\n",
    "En este caso podremos usar la sintaxis de `[start:stop:step]` que conocemos de listas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Oro</th>\n",
       "      <th>Plata</th>\n",
       "      <th>Bronce</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pa√≠s</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>China</th>\n",
       "      <td>1473</td>\n",
       "      <td>994</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jap√≥n</th>\n",
       "      <td>1032</td>\n",
       "      <td>1037</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corea del Sur</th>\n",
       "      <td>745</td>\n",
       "      <td>663</td>\n",
       "      <td>827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ir√°n</th>\n",
       "      <td>179</td>\n",
       "      <td>181</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kazajist√°n</th>\n",
       "      <td>155</td>\n",
       "      <td>158</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>India</th>\n",
       "      <td>154</td>\n",
       "      <td>202</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tailandia</th>\n",
       "      <td>132</td>\n",
       "      <td>175</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indonesia</th>\n",
       "      <td>112</td>\n",
       "      <td>131</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>China Taip√©i</th>\n",
       "      <td>99</td>\n",
       "      <td>144</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corea del Norte</th>\n",
       "      <td>91</td>\n",
       "      <td>120</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Oro  Plata  Bronce\n",
       "Pa√≠s                                \n",
       "China            1473    994     720\n",
       "Jap√≥n            1032   1037     985\n",
       "Corea del Sur     745    663     827\n",
       "Ir√°n              179    181     197\n",
       "Kazajist√°n        155    158     224\n",
       "India             154    202     315\n",
       "Tailandia         132    175     278\n",
       "Indonesia         112    131     240\n",
       "China Taip√©i       99    144     276\n",
       "Corea del Norte    91    120     235"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lo primero que vamos a hacer es recordar el DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejercicio vamos a querer sacar las medallas de Oro y Bronce desde la Ir√°n hasta Indonesia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las medallas de Oro y Bronce de Ir√°n hasta Indonesia usando el LOC son: \n",
      "              Oro  Bronce\n",
      "Pa√≠s                   \n",
      "Ir√°n        179     197\n",
      "Kazajist√°n  155     224\n",
      "India       154     315\n",
      "Tailandia   132     278\n",
      "Indonesia   112     240\n",
      "\n",
      "----------------------\n",
      "\n",
      "Las medallas de Oro y Bronce de Ir√°n hasta Indonesia usando el ILOC son: \n",
      "              Oro  Bronce\n",
      "Pa√≠s                   \n",
      "Ir√°n        179     197\n",
      "Kazajist√°n  155     224\n",
      "India       154     315\n",
      "Tailandia   132     278\n",
      "Indonesia   112     240\n"
     ]
    }
   ],
   "source": [
    "# Usando el loc, accediendo por los nombres de las filas y las columnas\n",
    "print(f\"Las medallas de Oro y Bronce de Ir√°n hasta Indonesia usando el LOC son: \\n  {df.loc['Ir√°n': 'Indonesia', [\"Oro\", \"Bronce\"] ]}\")\n",
    "\n",
    "print(\"\\n----------------------\\n\")\n",
    "# Usando el iloc, accediendo por los √≠ndices\n",
    "print(f'Las medallas de Oro y Bronce de Ir√°n hasta Indonesia usando el ILOC son: \\n  {df.iloc[3:8, [0,2]]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¬øY si quisieramos saber todas las medallas de China, Corea del Sur, Kazajist√°n y Tailandia? En este caso tendremos que hacer uso del `[start_ stop: step]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Oro</th>\n",
       "      <th>Plata</th>\n",
       "      <th>Bronce</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pa√≠s</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>China</th>\n",
       "      <td>1473</td>\n",
       "      <td>994</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jap√≥n</th>\n",
       "      <td>1032</td>\n",
       "      <td>1037</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corea del Sur</th>\n",
       "      <td>745</td>\n",
       "      <td>663</td>\n",
       "      <td>827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ir√°n</th>\n",
       "      <td>179</td>\n",
       "      <td>181</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kazajist√°n</th>\n",
       "      <td>155</td>\n",
       "      <td>158</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>India</th>\n",
       "      <td>154</td>\n",
       "      <td>202</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tailandia</th>\n",
       "      <td>132</td>\n",
       "      <td>175</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indonesia</th>\n",
       "      <td>112</td>\n",
       "      <td>131</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>China Taip√©i</th>\n",
       "      <td>99</td>\n",
       "      <td>144</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corea del Norte</th>\n",
       "      <td>91</td>\n",
       "      <td>120</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Oro  Plata  Bronce\n",
       "Pa√≠s                                \n",
       "China            1473    994     720\n",
       "Jap√≥n            1032   1037     985\n",
       "Corea del Sur     745    663     827\n",
       "Ir√°n              179    181     197\n",
       "Kazajist√°n        155    158     224\n",
       "India             154    202     315\n",
       "Tailandia         132    175     278\n",
       "Indonesia         112    131     240\n",
       "China Taip√©i       99    144     276\n",
       "Corea del Norte    91    120     235"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todas las medallas para China, Corea del Sur,  Kazajist√°n y Tailandia usando el LOC es: \n",
      "                  Oro  Plata  Bronce\n",
      "Pa√≠s                              \n",
      "China          1473    994     720\n",
      "Corea del Sur   745    663     827\n",
      "Kazajist√°n      155    158     224\n",
      "Tailandia       132    175     278\n",
      "\n",
      "----------------------\n",
      "\n",
      "Todas las medallas para China, Corea del Sur,  Kazajist√°n y Tailandia usando el ILOC es: \n",
      "                  Oro  Plata  Bronce\n",
      "Pa√≠s                              \n",
      "China          1473    994     720\n",
      "Corea del Sur   745    663     827\n",
      "Kazajist√°n      155    158     224\n",
      "Tailandia       132    175     278\n"
     ]
    }
   ],
   "source": [
    "# Usando el loc, accediendo por los nombres de las filas y las columnas\n",
    "print(f\"Todas las medallas para China, Corea del Sur,  Kazajist√°n y Tailandia usando el LOC es: \\n  {df.loc[\"China\":\"Tailandia\":2, :]}\")\n",
    "\n",
    "print(\"\\n----------------------\\n\")\n",
    "# Usando el iloc, accediendo por los √≠ndices\n",
    "print(f'Todas las medallas para China, Corea del Sur,  Kazajist√°n y Tailandia usando el ILOC es: \\n  {df.iloc[:7:2, :]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleccionar basado en una condici√≥n \n",
    "\n",
    "Al igual que en NumPy podemos filtrar los datos de nuestro **DataFrame** usando operadores de comparaci√≥n,  como `>`, `<`, `>=`, `<=`, `==` o `!=`. Pero antes de ponernos a ver como filtrar datos, aprendamos a acceder solo a una columna de nuestro **DataFrame**. Podr√≠amos pensar que lo podemos hacer con un `loc` o un `iloc` como hemos estado viendo hasta ahora, pero hay una forma un poco m√°s sencilla. Para eso deberemos seguir la siguiente sintaxis:\n",
    "\n",
    "```python\n",
    "df[\"nombre_columna\"]\n",
    "df.nombre_columna\n",
    "# estas dos opciones me devuelven exactamente lo mismo. \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Oro</th>\n",
       "      <th>Plata</th>\n",
       "      <th>Bronce</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pa√≠s</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>China</th>\n",
       "      <td>1473</td>\n",
       "      <td>994</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jap√≥n</th>\n",
       "      <td>1032</td>\n",
       "      <td>1037</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corea del Sur</th>\n",
       "      <td>745</td>\n",
       "      <td>663</td>\n",
       "      <td>827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ir√°n</th>\n",
       "      <td>179</td>\n",
       "      <td>181</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kazajist√°n</th>\n",
       "      <td>155</td>\n",
       "      <td>158</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>India</th>\n",
       "      <td>154</td>\n",
       "      <td>202</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tailandia</th>\n",
       "      <td>132</td>\n",
       "      <td>175</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indonesia</th>\n",
       "      <td>112</td>\n",
       "      <td>131</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>China Taip√©i</th>\n",
       "      <td>99</td>\n",
       "      <td>144</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corea del Norte</th>\n",
       "      <td>91</td>\n",
       "      <td>120</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Oro  Plata  Bronce\n",
       "Pa√≠s                                \n",
       "China            1473    994     720\n",
       "Jap√≥n            1032   1037     985\n",
       "Corea del Sur     745    663     827\n",
       "Ir√°n              179    181     197\n",
       "Kazajist√°n        155    158     224\n",
       "India             154    202     315\n",
       "Tailandia         132    175     278\n",
       "Indonesia         112    131     240\n",
       "China Taip√©i       99    144     276\n",
       "Corea del Norte    91    120     235"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recordamos el DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pa√≠s\n",
       "China              1473\n",
       "Jap√≥n              1032\n",
       "Corea del Sur       745\n",
       "Ir√°n                179\n",
       "Kazajist√°n          155\n",
       "India               154\n",
       "Tailandia           132\n",
       "Indonesia           112\n",
       "China Taip√©i         99\n",
       "Corea del Norte      91\n",
       "Name: Oro, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accedemos a los datos de la columna 'Oro'\n",
    "# Fijaos como nos ha devuelto una serie donde tenemos todos los valores de la columna 'Oro'\n",
    "df[\"Oro\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pa√≠s\n",
       "China              1473\n",
       "Jap√≥n              1032\n",
       "Corea del Sur       745\n",
       "Ir√°n                179\n",
       "Kazajist√°n          155\n",
       "India               154\n",
       "Tailandia           132\n",
       "Indonesia           112\n",
       "China Taip√©i         99\n",
       "Corea del Norte      91\n",
       "Name: Oro, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# El c√≥digo de arriba es exactamente igual que:\n",
    "df.Oro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¬øY que pasar√≠a si quisiera acceder a varias columnas? Solo podremos usar la sintaxis `df[[\"columna_1\", \"columna_2\"]]`. Fijaos como ahora estamos a√±adiendo un corchete extra a la sintaxis que hemos aprendido en los pasos anteriores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Oro</th>\n",
       "      <th>Bronce</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pa√≠s</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>China</th>\n",
       "      <td>1473</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jap√≥n</th>\n",
       "      <td>1032</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corea del Sur</th>\n",
       "      <td>745</td>\n",
       "      <td>827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ir√°n</th>\n",
       "      <td>179</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kazajist√°n</th>\n",
       "      <td>155</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>India</th>\n",
       "      <td>154</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tailandia</th>\n",
       "      <td>132</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indonesia</th>\n",
       "      <td>112</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>China Taip√©i</th>\n",
       "      <td>99</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corea del Norte</th>\n",
       "      <td>91</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Oro  Bronce\n",
       "Pa√≠s                         \n",
       "China            1473     720\n",
       "Jap√≥n            1032     985\n",
       "Corea del Sur     745     827\n",
       "Ir√°n              179     197\n",
       "Kazajist√°n        155     224\n",
       "India             154     315\n",
       "Tailandia         132     278\n",
       "Indonesia         112     240\n",
       "China Taip√©i       99     276\n",
       "Corea del Norte    91     235"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"Oro\", \"Bronce\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que hemos visto esto como acceder a los datos de una o varias columnas unicamente, vamos a ver como podemos filtrar los datos del **DataFrame**, igual que hac√≠amos en los *array*s. \n",
    "\n",
    "En este primer ejemplo, vamos a quedarnos con todos los datos donde las medallas de Oro  sean mayor que 1000. En este caso seguiremos la siguiente sintaxis: \n",
    "\n",
    "```python\n",
    "df.loc[df[\"columna\"] CONDICION]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El resultado usando la sintaxis de DF.COLUMNA usando LOC es:\n",
      "         Oro  Plata  Bronce\n",
      "Pa√≠s                      \n",
      "China  1473    994     720\n",
      "Jap√≥n  1032   1037     985\n",
      "\n",
      " --------------- \n",
      "\n",
      "El resultado usando la sintaxis de df['COLUMNA'] usando LOC es:\n",
      "         Oro  Plata  Bronce\n",
      "Pa√≠s                      \n",
      "China  1473    994     720\n",
      "Jap√≥n  1032   1037     985\n"
     ]
    }
   ],
   "source": [
    "# filtramos nuestros datos para quedarnos solo con las filas donde la temperatura sean mayor que 12\n",
    "df_mayor_1000_1 = df.loc[df.Oro > 1000, :]\n",
    "print(f\"El resultado usando la sintaxis de DF.COLUMNA usando LOC es:\\n {df_mayor_1000_1}\")\n",
    "\n",
    "print(\"\\n --------------- \\n\")\n",
    "\n",
    "# la linea de arriba es exactamente la misma que esta que vemos aqu√≠ abajo\n",
    "df_mayor_1000_2 = df.loc[df[\"Oro\"] > 1000, :]\n",
    "print(f\"El resultado usando la sintaxis de df['COLUMNA'] usando LOC es:\\n {df_mayor_1000_2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/Contenido/DataScience/lolo/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ¬øy como lo har√≠amos con iloc? Se nos ocurrir√≠a que usando los corchetes, poniendo el √≠ndice de la columna que queremos usar como filtro. \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# veamoslo. \u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df\u001b[38;5;241m.\u001b[39miloc[\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1000\u001b[39m, :]\n",
      "File \u001b[0;32m~/Documents/Contenido/DataScience/lolo/lib/python3.12/site-packages/pandas/core/frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Documents/Contenido/DataScience/lolo/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# ¬øy como lo har√≠amos con iloc? Se nos ocurrir√≠a que usando los corchetes, poniendo el √≠ndice de la columna que queremos usar como filtro. \n",
    "# veamoslo. \n",
    "df.iloc[df[0] > 1000, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è Obtenemos el error porque `iloc` no puede aceptar una Serie booleana. S√≥lo acepta una lista booleana. Podemos utilizar la funci√≥n `list()` para convertir una Serie en una lista booleana. Por lo tanto, tendr√≠amos que:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Oro</th>\n",
       "      <th>Plata</th>\n",
       "      <th>Bronce</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pa√≠s</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>China</th>\n",
       "      <td>1473</td>\n",
       "      <td>994</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jap√≥n</th>\n",
       "      <td>1032</td>\n",
       "      <td>1037</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Oro  Plata  Bronce\n",
       "Pa√≠s                      \n",
       "China  1473    994     720\n",
       "Jap√≥n  1032   1037     985"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[list(df.Oro > 1000), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El resultado usando la sintaxis de DF.COLUMNA usando LOC es:\n",
      "         Oro  Plata  Bronce\n",
      "Pa√≠s                      \n",
      "China  1473    994     720\n",
      "Jap√≥n  1032   1037     985\n",
      "\n",
      " --------------- \n",
      "\n",
      "El resultado usando la sintaxis de df['COLUMNA'] usando LOC es:\n",
      "         Oro  Plata  Bronce\n",
      "Pa√≠s                      \n",
      "China  1473    994     720\n",
      "Jap√≥n  1032   1037     985\n",
      "\n",
      " --------------- \n",
      "\n",
      "El resultado usando la sintaxis de df['COLUMNA'] usando ILOC es:\n",
      "         Oro  Plata  Bronce\n",
      "Pa√≠s                      \n",
      "China  1473    994     720\n",
      "Jap√≥n  1032   1037     985\n"
     ]
    }
   ],
   "source": [
    "# si juntamos todo lo aprendido de loc e iloc en las √∫ltimas celdas\n",
    "\n",
    "# filtramos nuestros datos para quedarnos solo con las filas donde el n√∫mero de medallas de Oro sea mayor que 1000\n",
    "df_mayor_1000_1 = df.loc[df.Oro > 1000, :]\n",
    "print(f\"El resultado usando la sintaxis de DF.COLUMNA usando LOC es:\\n {df_mayor_1000_1}\")\n",
    "\n",
    "print(\"\\n --------------- \\n\")\n",
    "\n",
    "# la linea de arriba es exactamente la misma que esta que vemos aqu√≠ abajo\n",
    "df_mayor_1000_2 = df.loc[df[\"Oro\"] > 1000, :]\n",
    "print(f\"El resultado usando la sintaxis de df['COLUMNA'] usando LOC es:\\n {df_mayor_1000_2}\")\n",
    "\n",
    "print(\"\\n --------------- \\n\")\n",
    "\n",
    "# filtramos con ILOC\n",
    "df_mayor_1000_iloc = df.iloc[list(df.Oro > 1000), :]\n",
    "print(f\"El resultado usando la sintaxis de df['COLUMNA'] usando ILOC es:\\n {df_mayor_1000_iloc}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¬øY si queremos que se cumplan varias condiciones?**\n",
    "\n",
    "En este caso tendremos que usar los operadores `&` o `|`, como vimos en NumPy. Recordemos lo que significan: \n",
    "\n",
    "- `&`: es como el operador `and`. En este caso se tendr√°n que cumplir todas las condiciones que le pasemos. \n",
    "\n",
    "- `|`: es como el operador `or`. En este caso nos devolver√° datos de las condiciones que se cumplan, pero tienen porque cumplirse todas a la vez. O una condici√≥n y otra. \n",
    "\n",
    "En este ejercicio vamos a querer filtrar  los pa√≠ses que tengan menos de 100 medallas de Oro  y m√°s de 900 de Bronce. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El resultado usando LOC es:\n",
      " Empty DataFrame\n",
      "Columns: [Oro, Plata, Bronce]\n",
      "Index: []\n",
      "\n",
      " --------------- \n",
      "\n",
      "El resultado usando ILOC es:\n",
      " Empty DataFrame\n",
      "Columns: [Oro, Plata, Bronce]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Seleccionar aquellas filas donde se cumpla la condici√≥n de que el viento es mayor que 20 y el tiempo era soleado.\n",
    "# adem√°s estamos especificando que nos devuelva solo las columnas de \"Temperature\" y \" Wind\"\n",
    "# SE TIENEN QUE CUMPLIR LAS DOS CONDICIONES\n",
    "\n",
    "# filtramos con LOC\n",
    "df_dos_condiciones_loc = df.loc[(df.Oro < 100) & (df.Bronce > 900), :]\n",
    "\n",
    "# filtramos con ILOC\n",
    "df_dos_condiciones_iloc = df.iloc[list((df.Oro < 100) & (df.Bronce > 900)), :]\n",
    "\n",
    "\n",
    "print(f\"El resultado usando LOC es:\\n {df_dos_condiciones_loc}\")\n",
    "\n",
    "print(\"\\n --------------- \\n\")\n",
    "\n",
    "print(f\"El resultado usando ILOC es:\\n {df_dos_condiciones_iloc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El resultado usando LOC es:\n",
      "                   Oro  Plata  Bronce\n",
      "Pa√≠s                                \n",
      "Jap√≥n            1032   1037     985\n",
      "China Taip√©i       99    144     276\n",
      "Corea del Norte    91    120     235\n",
      "\n",
      " --------------- \n",
      "\n",
      "El resultado usando ILOC es:\n",
      "                   Oro  Plata  Bronce\n",
      "Pa√≠s                                \n",
      "Jap√≥n            1032   1037     985\n",
      "China Taip√©i       99    144     276\n",
      "Corea del Norte    91    120     235\n"
     ]
    }
   ],
   "source": [
    "# hag√°moslo ahora con un or (|)\n",
    "# SE TIENE QUE CUMPLIR UNA CONDICI√ìN U OTRA\n",
    "\n",
    "# filtramos con LOC\n",
    "df_dos_condiciones_loc_or = df.loc[(df.Oro < 100) | (df.Bronce > 900), :]\n",
    "\n",
    "# filtramos con ILOC\n",
    "df_dos_condiciones_iloc_or = df.iloc[list((df.Oro < 100) | (df.Bronce > 900)), :]\n",
    "\n",
    "\n",
    "print(f\"El resultado usando LOC es:\\n {df_dos_condiciones_loc_or}\")\n",
    "\n",
    "print(\"\\n --------------- \\n\")\n",
    "\n",
    "print(f\"El resultado usando ILOC es:\\n {df_dos_condiciones_iloc_or}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**POR LO TANTO, LAS DIFERENCIAS ENTRE `LOC` E `ILOC` SON:**\n",
    "\n",
    "|       | loc                                             | iloc                                                |\n",
    "|-------|-------------------------------------------------|-----------------------------------------------------|\n",
    "| Uso   | Acceso a datos utilizando etiquetas de √≠ndice    | Acceso a datos utilizando posiciones de √≠ndice       |\n",
    "| √çndice| Puede utilizar etiquetas o slices de etiquetas   | Solo puede utilizar posiciones enteras o slices      |\n",
    "| Filtrado | Permite filtrar filas y seleccionar columnas     | Permite filtrar filas y seleccionar columnas         |\n",
    "| Sintaxis | Utiliza etiquetas separadas por comas           | Utiliza posiciones enteras separadas por comas       |\n",
    "| Ejemplo | `df.loc[3:5, 'columna']`                        | `df.iloc[3:5, 2]`                                   |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Tabla de Contenidos",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "326.663px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
