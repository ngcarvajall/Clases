{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"https://github.com/Hack-io-Data/Imagenes/blob/main/01-LogosHackio/logo_naranja@4x.png?raw=true\" alt=\"esquema\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Tabla de Contenidos<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introducción-a-Pandas\" data-toc-modified-id=\"Introducción-a-Pandas-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introducción a Pandas</a></span><ul class=\"toc-item\"><li><span><a href=\"#¿Qué-es-Pandas-y-por-qué-es-importante?\" data-toc-modified-id=\"¿Qué-es-Pandas-y-por-qué-es-importante?-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>¿Qué es Pandas y por qué es importante?</a></span></li></ul></li><li><span><a href=\"#Series-de-Pandas\" data-toc-modified-id=\"Series-de-Pandas-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Series de Pandas</a></span><ul class=\"toc-item\"><li><span><a href=\"#¿Qué-es-una-Serie?\" data-toc-modified-id=\"¿Qué-es-una-Serie?-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>¿Qué es una Serie?</a></span></li><li><span><a href=\"#Creación-de-Series\" data-toc-modified-id=\"Creación-de-Series-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Creación de Series</a></span></li><li><span><a href=\"#Propiedades-de-las-Series\" data-toc-modified-id=\"Propiedades-de-las-Series-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Propiedades de las Series</a></span></li><li><span><a href=\"#Indexación-de-las-Series\" data-toc-modified-id=\"Indexación-de-las-Series-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Indexación de las Series</a></span></li></ul></li><li><span><a href=\"#DataFrames-en-Pandas\" data-toc-modified-id=\"DataFrames-en-Pandas-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>DataFrames en Pandas</a></span><ul class=\"toc-item\"><li><span><a href=\"#¿Qué-es-un-DataFrame?\" data-toc-modified-id=\"¿Qué-es-un-DataFrame?-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>¿Qué es un DataFrame?</a></span></li><li><span><a href=\"#Creación-de-DataFrames\" data-toc-modified-id=\"Creación-de-DataFrames-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Creación de DataFrames</a></span></li><li><span><a href=\"#Lectura-de-archivos-en-Pandas\" data-toc-modified-id=\"Lectura-de-archivos-en-Pandas-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Lectura de archivos en Pandas</a></span></li><li><span><a href=\"#pd.read_csv():\" data-toc-modified-id=\"pd.read_csv():-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span><code>pd.read_csv()</code>:</a></span></li><li><span><a href=\"#pd.read_excel()\" data-toc-modified-id=\"pd.read_excel()-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span><code>pd.read_excel()</code></a></span></li><li><span><a href=\"#pd.read_json()\" data-toc-modified-id=\"pd.read_json()-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span><code>pd.read_json()</code></a></span></li><li><span><a href=\"#pd.read_pickle\" data-toc-modified-id=\"pd.read_pickle-3.7\"><span class=\"toc-item-num\">3.7&nbsp;&nbsp;</span><code>pd.read_pickle</code></a></span></li><li><span><a href=\"#Indexación-en-Pandas-(loc-e-iloc)\" data-toc-modified-id=\"Indexación-en-Pandas-(loc-e-iloc)-3.8\"><span class=\"toc-item-num\">3.8&nbsp;&nbsp;</span>Indexación en Pandas (<code>loc</code> e <code>iloc</code>)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Selección-a-través-de-un-único-elemento\" data-toc-modified-id=\"Selección-a-través-de-un-único-elemento-3.8.1\"><span class=\"toc-item-num\">3.8.1&nbsp;&nbsp;</span>Selección a través de un único elemento</a></span></li><li><span><a href=\"#Selección-a-través-de-una-lista-de-valores\" data-toc-modified-id=\"Selección-a-través-de-una-lista-de-valores-3.8.2\"><span class=\"toc-item-num\">3.8.2&nbsp;&nbsp;</span>Selección a través de una lista de valores</a></span></li><li><span><a href=\"#Selección-de-un-rango-de-datos-a-través-de-un-corte\" data-toc-modified-id=\"Selección-de-un-rango-de-datos-a-través-de-un-corte-3.8.3\"><span class=\"toc-item-num\">3.8.3&nbsp;&nbsp;</span>Selección de un rango de datos a través de un corte</a></span></li><li><span><a href=\"#Seleccionar-basado-en-una-condición\" data-toc-modified-id=\"Seleccionar-basado-en-una-condición-3.8.4\"><span class=\"toc-item-num\">3.8.4&nbsp;&nbsp;</span>Seleccionar basado en una condición</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción a Pandas\n",
    "\n",
    "## ¿Qué es Pandas y por qué es importante?\n",
    "\n",
    "`Pandas` es una biblioteca de Python utilizada para el análisis de datos y la manipulación de estructuras de datos tabulares, es decir, en formato de tablas. Nos ofrece una gran cantidad de funciones y herramientas para trabajar con datos de forma eficiente y efectiva. Algunas de las razones por las que Pandas es importante son:\n",
    "\n",
    "- Define nuevas estructuras de datos basadas en los **array*s* de la biblioteca NumPy, pero con funcionalidades adicionales. Esto significa que podemos aprovechar las capacidades de NumPy y agregar nuevas funcionalidades específicas para el análisis de datos.\n",
    "  \n",
    "- Permite la carga y manipulación de datos de diferentes fuentes, como archivos CSV, Excel, bases de datos SQL, entre otros.\n",
    "  \n",
    "- Proporciona funciones para explorar y entender rápidamente la estructura y contenido de los datos.\n",
    "\n",
    "- Facilita la limpieza y transformación de datos, lo que es fundamental para garantizar la calidad de los datos antes del análisis.\n",
    "\n",
    "- Ofrece herramientas para realizar análisis estadísticos, visualizaciones y modelado de datos.\n",
    "\n",
    "- Permite acceder a los datos mediante índices o nombres para filas y columnas. Esto significa que puedes acceder a los datos utilizando etiquetas en lugar de solo posiciones numéricas, lo cual es especialmente útil cuando los datos están etiquetados o indexados de manera significativa.\n",
    "\n",
    "- Ofrece métodos para reordenar, dividir y combinar conjuntos de datos. Puedes realizar operaciones como clasificación, filtrado y combinación de datos para obtener resultados específicos o realizar análisis más avanzados.\n",
    "\n",
    "En cuanto a las estructuras de datos en Pandas, existen tres principales:\n",
    "\n",
    "1. `Series`: Representa una estructura de datos unidimensional similar a un *array* o una columna en una tabla. Cada elemento en una Serie tiene un índice asociado que permite acceder a los datos de forma individual.\n",
    "\n",
    "\n",
    "2. `DataFrame`: Representa una estructura de datos bidimensional similar a una tabla de una base de datos o una hoja de cálculo de Excel. Consiste en una colección de Series organizadas en columnas. Los *DataFrame*s son especialmente útiles para el análisis de datos tabulares y ofrecen una gran cantidad de funcionalidades para manipular y analizar los datos.\n",
    "\n",
    "\n",
    "3. `Panel`: Representa una estructura de datos tridimensional, aunque su uso no es tan común como las *Series* y los *DataFrame*s. Puede considerarse como una colección de *DataFrame*s.\n",
    "\n",
    "Antes de ponernos a trabajar con Pandas, lo primero que tendremos que hacer es instalar la librería usando `pip` o `pip3`: \n",
    "\n",
    "```bash\n",
    "pip install pandas\n",
    "\n",
    "pip3 install pandas\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamiento de datos\n",
    "# ==============================================================================\n",
    "import pandas as pd\n",
    "\n",
    "# Ignorar warnings\n",
    "# ==============================================================================\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# Configuración\n",
    "# -----------------------------------------------------------------------\n",
    "pd.set_option('display.max_columns', None) # para poder visualizar todas las columnas de los DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Series de Pandas\n",
    "\n",
    "## ¿Qué es una Serie?\n",
    "\n",
    "\n",
    "Como hemos dicho, una **Serie** es una estructura de datos unidimensional en **Pandas**. Se puede pensar en una **Serie** como una columna en una tabla  con etiquetas de índice. Cada elemento en una **Serie** tiene un índice asociado que permite acceder a los datos de forma individual.\n",
    "\n",
    "Las Series en Pandas tienen las siguientes características:\n",
    "\n",
    "1. **Datos homogéneos**: Contiene datos de **un solo tipo**, como *integer*s, *float*s, *strings*, etc. \n",
    "\n",
    "2. **Índices etiquetados**: Cada elemento en una **Serie** tiene una etiqueta de índice asociada. Los índices pueden ser etiquetas personalizadas o valores numéricos generados automáticamente. Estas etiquetas permiten un acceso más intuitivo a los datos en lugar de depender solo de las posiciones numéricas.\n",
    "\n",
    "3. **Funcionalidades adicionales**: Proporcionan numerosas funcionalidades para manipular y analizar datos de manera eficiente. Puedes realizar operaciones matemáticas, filtrado de datos, agregación, ordenamiento, alineación de datos, entre otras.\n",
    "\n",
    "Es importante destacar que las **Series** y los **DataFrames** son los elementos fundamentales en el ecosistema de Pandas, y muchas operaciones de análisis de datos se realizan utilizando estas estructuras de datos.\n",
    "\n",
    "\n",
    "## Creación de Series\n",
    "\n",
    "Podemos crear Series de distintas formas: \n",
    "\n",
    "- Series vacías.\n",
    "\n",
    "- Series a partir de un **array**. Recordamos, las **Series** son unidimensionales, por lo tanto solo le podremos pasar **array*s* unidimensionales.\n",
    "\n",
    "- Series a partir de listas.\n",
    "\n",
    "- Series a partir de un diccionario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------ SERIES VACÍAS ------ \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], dtype: object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creemos algunas Series en Pandas para entenderlas mejor.\n",
    "# en este primer ejemplo crearemos una Serie vacía\n",
    "\n",
    "print(\" ------ SERIES VACÍAS ------ \")\n",
    "serie_vacia = pd.Series()\n",
    "serie_vacia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------ SERIES a partir de LISTAS ------ \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    109\n",
       "1     78\n",
       "2      4\n",
       "3    189\n",
       "4     98\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\" ------ SERIES a partir de LISTAS ------ \")\n",
    "\n",
    "# definimos la lista\n",
    "lista = [109,78, 4, 189, 98]\n",
    "\n",
    "# convertimos esta lista en una Serie\n",
    "serie_lista1 = pd.Series(lista)\n",
    "serie_lista1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📌 Si nos fijamos el método `pd.Series` nos va a generar automáticamente el índice y lo crea con números consecutivos, empezando por el 0. Sin embargo, también le podemos pasar los índices que queremos usando el parámetro `index`. Tener índices personalizados puede ser útil cuando necesitamos acceder a los elementos de la **Serie** utilizando etiquetas específicas en lugar de las posiciones numéricas predeterminadas. Esto facilita la manipulación y el análisis de los datos. \n",
    "\n",
    "\n",
    "\n",
    "> index: Es un parámetro opcional de la función `pd.Series`. En este caso, se proporciona una lista de índices personalizados para la Serie. Los índices indican cómo se etiquetarán los elementos de la Serie. En este ejemplo, los índices se definen en el orden especificado: 3, 4, 5, 6, 7, 8, 9, 1, 2.\n",
    ">\n",
    "> Es importante destacar que los índices pueden ser de diferentes tipos, incluidos *integer*s, cadenas, fechas, etc. Además, los índices no necesariamente tienen que estar en orden o ser consecutivos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------ SERIES a partir de LISTAS ESPECIFICANDO ÍNDICE NÚMERICO ------ \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3    109\n",
       "4     78\n",
       "5      4\n",
       "6    189\n",
       "7     98\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------ SERIES a partir de LISTAS ESPECIFICANDO ÍNDICE STRING ------ \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Lunes        109\n",
       "Martes        78\n",
       "Miercoles      4\n",
       "Jueves       189\n",
       "Viernes       98\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\" ------ SERIES a partir de LISTAS ESPECIFICANDO ÍNDICE NÚMERICO ------ \")\n",
    "# vamos a definir una nueva serie pero en este caso vamos a ponerle nuestro propio índice usando el parámetro 'index'\n",
    "serie_lista2 = pd.Series(lista, index = [3,4,5,6,7])\n",
    "display(serie_lista2)\n",
    "\n",
    "print(\" ------ SERIES a partir de LISTAS ESPECIFICANDO ÍNDICE STRING ------ \")\n",
    "\n",
    "# como hemos mencionado los índices pueden ser de distintos tipos, en este caso crearemos una nueva Serie donde sus índices sean strings\n",
    "serie_lista3 = pd.Series(lista, index = [\"Lunes\",\"Martes\",\"Miercoles\",\"Jueves\",\"Viernes\"])\n",
    "display(serie_lista3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------ SERIES a partir de DICCIONARIOS ------ \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Manolo     20\n",
       "Lorena    220\n",
       "Paula     198\n",
       "Lola       78\n",
       "Marta     167\n",
       "Pablo      48\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\" ------ SERIES a partir de DICCIONARIOS ------ \")\n",
    "\n",
    "# definir un diccionario \n",
    "dicc = {'Manolo' : 20, \n",
    "        'Lorena' : 220, \n",
    "        'Paula' : 198, \n",
    "        'Lola': 78, \n",
    "       'Marta': 167, \n",
    "        'Pablo': 48} \n",
    "\n",
    "# crear una serie nueva a partir del diccionario definido previamente\n",
    "serie_diccionario = pd.Series(dicc)\n",
    "serie_diccionario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propiedades de las Series\n",
    "\n",
    "Las propiedades son atributos específicos que nos proporcionan información sobre las características de una **Serie** en particular. Las propiedades más importantes de las **Series** :\n",
    "\n",
    "1. `values`: Devuelve los valores de la **Serie** como un *array* NumPy. Podemos acceder a ellos utilizando la sintaxis `serie.values`.\n",
    "\n",
    "2. `index`: Devuelve los índices de la **Serie**. Como hemos dicho, los índices pueden ser de cualquier tipo, incluyendo *integer*s, *strings* u otros tipos o estructuras de datos. Podemos acceder a ellos utilizando la sintaxis `serie.index`.\n",
    "\n",
    "3. `dtype`: Devuelve el tipo de datos de los elementos en la Serie. Usaremos la sintaxis `serie.dtype`. Los tipos de datos más comunes que podemos encontrar en una Serie son `int64`, `float64`, `object` (que es el *string* que conocemos de Python básico), `datetime64`, entre otros.\n",
    "\n",
    "4. `size`: Devuelve el número total de elementos en la Serie. Usaremos la sintaxis `serie.size`.\n",
    "\n",
    "5. `shape`: Devuelve una tupla que representa la forma (dimensiones) de la **Serie**. En el caso de una **Serie** unidimensional, la forma será `(n,)`, donde `n` es el número de elementos en la Serie. Usaremos la sintaxis `serie.shape`.\n",
    "\n",
    "Estas propiedades son útiles para obtener información sobre una **Serie** en particular, como el tipo de datos, el número de elementos y los índices asociados. Además, las propiedades pueden ser utilizadas en conjunto con los métodos y funciones de Pandas para realizar operaciones y análisis más avanzados en los datos de la **Serie**.\n",
    "\n",
    "Es importante tener en cuenta que las **Series** son inmutables, lo que significa que no podemos cambiar sus elementos directamente. Sin embargo, podremos realizar operaciones y manipulaciones para obtener nuevos resultados o modificar la estructura de los datos en función de nuestras necesidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'La serie con la que vamos a trabajar es:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Manolo     20\n",
       "Lorena    220\n",
       "Paula     198\n",
       "Lola       78\n",
       "Marta     167\n",
       "Pablo      48\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "El método 'index' nos devuelve los índices de la Serie: Index(['Manolo', 'Lorena', 'Paula', 'Lola', 'Marta', 'Pablo'], dtype='object')\n",
      "---------------------------\n",
      "El método 'values' nos devuelve los valores de la Serie: [ 20 220 198  78 167  48]\n",
      "---------------------------\n",
      "El método 'shape' nos devuelve la forma de la Serie: (6,)\n",
      "---------------------------\n",
      "El método 'size' nos devuelve el número de elementos de la Serie: 6\n",
      "---------------------------\n",
      "El método 'dtypes' nos devuelve el tipo de datos de la Serie: int64\n"
     ]
    }
   ],
   "source": [
    "# recordemos la serie\n",
    "display(\"La serie con la que vamos a trabajar es:\", serie_diccionario)\n",
    "print(\"---------------------------\")\n",
    "\n",
    "# utilizamos el método index que nos va a devolver todos los índices \n",
    "# fijaos como en este caso nos ha devuelto todos los índices de nuestra Serie, es decir, los nombres de las alumnas\n",
    "print(f\"El método 'index' nos devuelve los índices de la Serie: {serie_diccionario.index}\")\n",
    "print(\"---------------------------\")\n",
    "\n",
    "# ahora utilizamos el método 'values' nos devuelve todos los valores de la Serie\n",
    "# en este caso los números que teníamos\n",
    "print(f\"El método 'values' nos devuelve los valores de la Serie: {serie_diccionario.values}\")\n",
    "print(\"---------------------------\")\n",
    "\n",
    "#utilizando el método 'shape' nos devuelve el número de \"filas\" que tenemos en la Serie\n",
    "print(f\"El método 'shape' nos devuelve la forma de la Serie: {serie_diccionario.shape}\")\n",
    "print(\"---------------------------\")\n",
    "\n",
    "#utilizando el método 'size' nos devuelve el número de elementos que tenemos en la Serie\n",
    "print(f\"El método 'size' nos devuelve el número de elementos de la Serie: {serie_diccionario.size}\")\n",
    "print(\"---------------------------\")\n",
    "\n",
    "#utilizando el método 'dtypes' nos devuelve el tipo de datos de la Serie\n",
    "print(f\"El método 'dtypes' nos devuelve el tipo de datos de la Serie: {serie_diccionario.dtypes}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexación de las Series\n",
    "\n",
    "La indexación se refiere a la forma en que accedemos a los elementos de una **Serie** utilizando índices o etiquetas. Pandas ofrece varias opciones para indexar y seleccionar elementos. Algunas de las principales formas de realizar la indexación en las Series son:\n",
    "\n",
    "-  **Indexación por posición**: Podemos acceder a los elementos de una **Serie** utilizando la posición numérica del elemento en la Serie, como hacíamos con las listas\n",
    "\n",
    "-  **Indexación por etiqueta**: Podemos acceder a los elementos de una **Serie** utilizando las etiquetas de índice asociadas a cada elemento. \n",
    "\n",
    "-  **Indexación por rango**: Podemos acceder a un rango de elementos de una **Serie** utilizando los índices de inicio y fin. \n",
    "\n",
    "- **Indexación por lista de índices**: Podemos acceder a varios elementos de una **Serie** utilizando una lista de índices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ##### INDEXACIÓN POR POSICIÓN #####\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'La serie con la que vamos a trabajar es:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Manolo     20\n",
       "Lorena    220\n",
       "Paula     198\n",
       "Lola       78\n",
       "Marta     167\n",
       "Pablo      48\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "El valor que está en posición 0 es: 20\n",
      "---------------------------\n",
      "El valor que está en posición 2 es: 198\n"
     ]
    }
   ],
   "source": [
    "print(\" ##### INDEXACIÓN POR POSICIÓN #####\")\n",
    "display(\"La serie con la que vamos a trabajar es:\", serie_diccionario)\n",
    "print(\"---------------------------\")\n",
    "\n",
    "# accedemos al primer elemento (10). 🚨 Fijaos como los índices son como los de las listas, empiezan en 0\n",
    "print(\"El valor que está en posición 0 es:\", serie_diccionario[0])  \n",
    "print(\"---------------------------\")\n",
    "\n",
    "# accedemos al tercer elemento (30)\n",
    "print(\"El valor que está en posición 2 es:\", serie_diccionario[2])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ##### INDEXACIÓN POR ETIQUETA #####\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'La serie con la que vamos a trabajar es:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Manolo     20\n",
       "Lorena    220\n",
       "Paula     198\n",
       "Lola       78\n",
       "Marta     167\n",
       "Pablo      48\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "El valor que está en posición 0 es: 78\n",
      "---------------------------\n",
      "El valor que está en posición 2 es: 48\n"
     ]
    }
   ],
   "source": [
    "print(\" ##### INDEXACIÓN POR ETIQUETA #####\")\n",
    "display(\"La serie con la que vamos a trabajar es:\", serie_diccionario)\n",
    "print(\"---------------------------\")\n",
    "\n",
    "\n",
    "# accedemos al valor de la etiqueta de \"Lola\" (78). 🚨 Esto lo podríamos comparar con los diccionarios\n",
    "print(\"El valor que está en posición 0 es:\", serie_diccionario[\"Lola\"])  \n",
    "print(\"---------------------------\")\n",
    "\n",
    "# accedemos al valor de la etiqueta de \"Pablo\" (48). \n",
    "print(\"El valor que está en posición 2 es:\", serie_diccionario[\"Pablo\"])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ##### INDEXACIÓN POR RANGO #####\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'La serie con la que vamos a trabajar es:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Manolo     20\n",
       "Lorena    220\n",
       "Paula     198\n",
       "Lola       78\n",
       "Marta     167\n",
       "Pablo      48\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Los valores de los índices que están entre las posiciones 1 y 3 (incluida) es: \n",
      " Lorena    220\n",
      "Paula     198\n",
      "Lola       78\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\" ##### INDEXACIÓN POR RANGO #####\")\n",
    "display(\"La serie con la que vamos a trabajar es:\", serie_diccionario)\n",
    "print(\"---------------------------\")\n",
    "\n",
    "# accedemos a los elementos desde el índice 1 al 3 ([220, 198, 78]). 🚨 De niuevo fijaos como esto funciona igual que en listas\n",
    "# nos esta incluyendo el valor que está en el índice 1, pero no el que está en el índice 4\n",
    "print(\"Los valores de los índices que están entre las posiciones 1 y 3 (incluida) es: \\n\", serie_diccionario[1:4])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ##### INDEXACIÓN POR LISTA DE ÍNDICES #####\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'La serie con la que vamos a trabajar es:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Manolo     20\n",
       "Lorena    220\n",
       "Paula     198\n",
       "Lola       78\n",
       "Marta     167\n",
       "Pablo      48\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Los valores de los índices que están en las posiciones 1,3, y 4 son: \n",
      " Manolo     20\n",
      "Paula     198\n",
      "Lola       78\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\" ##### INDEXACIÓN POR LISTA DE ÍNDICES #####\")\n",
    "display(\"La serie con la que vamos a trabajar es:\", serie_diccionario)\n",
    "print(\"---------------------------\")\n",
    "\n",
    "# accedemos a los elementos con índices 1, 3 y 4. 🚨 Fijaos como en este caso, le hemos puesto dos corchetes\n",
    "print(\"Los valores de los índices que están en las posiciones 1,3, y 4 son: \\n\", serie_diccionario[[0,2,3]])  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrames en Pandas\n",
    "\n",
    "## ¿Qué es un DataFrame?\n",
    "\n",
    "Un **DataFrame** es una estructura de datos bidimensional en forma de tabla, similar a una hoja de cálculo o una base de datos relacional. Es una de las estructuras de datos más utilizadas en el análisis de datos con Pandas.\n",
    "\n",
    "Las principales características de los **DataFrames** son:\n",
    "\n",
    "1. **Estructura tabular**: Están organizados en filas y columnas. Cada columna representa una variable o característica, y cada fila representa una observación o entrada de datos. Esto facilita la visualización y el manejo de los datos en forma tabular.\n",
    "\n",
    "2. **Flexibilidad**: Al contrario que las Series, los **DataFrames** pueden contener datos de diferentes tipos, como *integer*s, *float*s, *strings*, fechas, *bool*s, entre otros. Además, las columnas pueden tener nombres personalizados y los índices pueden ser etiquetados con valores personalizados.\n",
    "\n",
    "3. **Operaciones eficientes**: Los **DataFrames** están diseñados para realizar operaciones eficientes en grandes conjuntos de datos. Ofrecen una amplia gama de funciones y métodos para manipular y analizar datos de manera rápida y eficiente.\n",
    "\n",
    "4. **Facilidad de importación y exportación**: Los **DataFrames** pueden leer y escribir datos en diversos formatos, como CSV, Excel, archivos de texto, bases de datos SQL, JSON, entre otros. Esto facilita la importación y exportación de datos desde y hacia diferentes fuentes de datos.\n",
    "\n",
    "5. **Indexación flexible**: Los **DataFrames** permiten acceder y manipular los datos utilizando diversas técnicas de indexación, como indexación por posición, indexación por etiqueta, indexación booleana y más. Esto permite seleccionar y filtrar datos de manera precisa y eficiente.\n",
    "\n",
    "## Creación de DataFrames\n",
    "\n",
    "En Pandas, podemos crear **DataFrames** a partir de una variedad de fuentes de datos. Las formas más comunes para crear *DataFrames* son:\n",
    "\n",
    "1. **A partir de un diccionario de listas**: Podemos crear un **DataFrame** a partir de un diccionario de listas, donde cada clave representa una columna y cada valor es una lista representa los valores de esa columna. \n",
    "\n",
    "2. **A partir de una lista de diccionarios**: Podemos crear un **DataFrame** a partir de una lista de diccionarios, donde cada diccionario representa una fila y las claves del diccionario representan las columnas. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------ DATAFRAMES a partir de DICCIONARIO ------ \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nombre</th>\n",
       "      <th>Edad</th>\n",
       "      <th>Ciudad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lola</td>\n",
       "      <td>34</td>\n",
       "      <td>Londres</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Manolo</td>\n",
       "      <td>89</td>\n",
       "      <td>Madrid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pablo</td>\n",
       "      <td>12</td>\n",
       "      <td>Roma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>María</td>\n",
       "      <td>52</td>\n",
       "      <td>Paris</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Nombre  Edad   Ciudad\n",
       "0    Lola    34  Londres\n",
       "1  Manolo    89   Madrid\n",
       "2   Pablo    12     Roma\n",
       "3   María    52    Paris"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\" ------ DATAFRAMES a partir de DICCIONARIO ------ \")\n",
    "\n",
    "# definimos un diccionario que luego convertiremos a DataFrame. Recordemos que esta era la forma que utilizamos en las lecciones del módulo 2 de web scraping\n",
    "data_diccionario = {\n",
    "    'Nombre': ['Lola', 'Manolo', 'Pablo', 'María'],\n",
    "    'Edad': [34, 89, 12, 52],\n",
    "    'Ciudad': ['Londres', 'Madrid', 'Roma', 'Paris']\n",
    "}\n",
    "\n",
    "# convertimos el diccionario en DataFrame usando el método 'pd.DataFrame'\n",
    "df_diccionario = pd.DataFrame(data_diccionario)\n",
    "\n",
    "# mostramos el DataFrame. Recordad que para ver las 5 primeras filas usaremos el método '.head()' \n",
    "df_diccionario.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------ DATAFRAMES a partir de LISTA ------ \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nombre</th>\n",
       "      <th>Edad</th>\n",
       "      <th>Ciudad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sofía</td>\n",
       "      <td>22</td>\n",
       "      <td>México DF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Luis</td>\n",
       "      <td>27</td>\n",
       "      <td>Guadalajara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Laura</td>\n",
       "      <td>33</td>\n",
       "      <td>Monterrey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Carlos</td>\n",
       "      <td>29</td>\n",
       "      <td>Puebla</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Nombre  Edad       Ciudad\n",
       "0   Sofía    22    México DF\n",
       "1    Luis    27  Guadalajara\n",
       "2   Laura    33    Monterrey\n",
       "3  Carlos    29       Puebla"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\" ------ DATAFRAMES a partir de LISTA ------ \")\n",
    "\n",
    "# definimos una lista de diccionarios que luego usaremos para convertir en DataFrame\n",
    "data_lista = [\n",
    "    {'Nombre': 'Sofía', 'Edad': 22, 'Ciudad': 'México DF'},\n",
    "    {'Nombre': 'Luis', 'Edad': 27, 'Ciudad': 'Guadalajara'},\n",
    "    {'Nombre': 'Laura', 'Edad': 33, 'Ciudad': 'Monterrey'},\n",
    "    {'Nombre': 'Carlos', 'Edad': 29, 'Ciudad': 'Puebla'}\n",
    "]\n",
    "\n",
    "\n",
    "# usamos el método 'pd.DataFrame' para convertir la lista de diccionarios a DataFrame\n",
    "df_lista = pd.DataFrame(data_lista)\n",
    "\n",
    "# mostramos el DataFrame, en este caso usaremos el método '.tail()' para mostrar las últimas 5 filas. \n",
    "df_lista.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura de archivos en Pandas\n",
    "\n",
    "En Pandas, disponemos de diversos métodos para abrir y leer diferentes tipos de archivos. Algunos de los métodos más comunes utilizados para la lectura de archivos en Pandas:\n",
    "\n",
    "- `pd.read_csv`\n",
    "\n",
    "- `pd.read_excel`\n",
    "\n",
    "- `pd.read_json`\n",
    "\n",
    "- `pd.read_pickle`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pd.read_csv()`: \n",
    "\n",
    "Nos va a permitir leer archivos csv, su sintaxis básica es: \n",
    "\n",
    "```python\n",
    "pd.read_csv(ruta_al_fichero , sep=',', delimiter=None, header='infer', names=None, index_col=None, dtype=None)\n",
    "```\n",
    "\n",
    "¿Qué significan todos estos parámetros?\n",
    "\n",
    "- `ruta_al_fichero`: La dirección de tu archivo CSV que queremos leer.\n",
    "\n",
    "- `sep` (opcional): Para indicarle a Pandas cómo están separados los datos en nuestro archivo. Normalmente es una coma, pero si es algo diferente, aquí es donde deberíamos cambiarlo.\n",
    "\n",
    "- `delimiter` (opcional): Es lo mismo que `sep`, solo que con un nombre diferente. Puedes usar cualquiera de los dos.\n",
    "\n",
    "- `header` (opcional): Indicará la fila del archivo CSV que queremos que sea el encabezado del **DataFrame**. Puede tomar los siguientes valores:\n",
    "  \n",
    "  - `None`: No hay encabezado y los datos se leerán sin nombres de columna.\n",
    "  \n",
    "  - `'infer'`: Intentará inferir automáticamente los nombres de columna del archivo, este es el que esta por defecto.\n",
    "\n",
    "  - Un número *integer* que especifica la fila del archivo que se utilizará como encabezado de columna (por ejemplo, `header=0`).\n",
    " \n",
    "\n",
    "- `names` (opcional): Si quieres cambiar los nombres de las columnas por algo más específico. Debe ser una lista.Si se proporciona, reemplazará los nombres inferidos o los nombres de columna del archivo.\n",
    "\n",
    "  \n",
    "- `index_col` (opcional): Especifica la columna (o columnas) que se utilizará/n como índice del **DataFrame**. Puede ser un número *integer*, una cadena con el nombre de la columna o una lista de columnas.\n",
    "\n",
    "- `dtype` (opcional): Esto es para especificar el tipo de datos de tus columnas. \n",
    "\n",
    "- `usecols` (opcional): Carga solo columnas especificadas, las columnas deben ser pasadas en formato lista. \n",
    "  \n",
    "  \n",
    "Estos son solo los conceptos básicos, pero `pd.read_csv()` tiene un montón más de trucos en la manga, como saltarse filas, manejar valores nulos y más. Puedes echar un vistazo a la documentación oficial [aquí](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html) para descubrir más sobre todas las cosas geniales que puedes hacer con esta función."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Datos/Pandas/aire.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_jobs \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../Datos/Pandas/aire.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m df_jobs\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Datos/Pandas/aire.csv'"
     ]
    }
   ],
   "source": [
    "df_jobs = pd.read_csv(\"../Datos/Pandas/aire.csv\")\n",
    "df_jobs.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como la propia definición indica, nuestras columnas deben ir separadas por comas. A veces, puede ocurrir que no vengan separados por comas. Como en el csv que acabamos de abrir. Y es que si nos fijamos nuestras columnas están separadas por `;`. ¿Cómo podemos solucionar esto? \n",
    "\n",
    "> Usando el parámetro `sep` de `pd.read_csv` donde tendremos que especificar por qué están separadas mis columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>provincia</th>\n",
       "      <th>municipio</th>\n",
       "      <th>estacion</th>\n",
       "      <th>magnitud</th>\n",
       "      <th>punto_muestreo</th>\n",
       "      <th>ano</th>\n",
       "      <th>mes</th>\n",
       "      <th>dia</th>\n",
       "      <th>h01</th>\n",
       "      <th>v01</th>\n",
       "      <th>h02</th>\n",
       "      <th>v02</th>\n",
       "      <th>h03</th>\n",
       "      <th>v03</th>\n",
       "      <th>h04</th>\n",
       "      <th>v04</th>\n",
       "      <th>h05</th>\n",
       "      <th>v05</th>\n",
       "      <th>h06</th>\n",
       "      <th>v06</th>\n",
       "      <th>h07</th>\n",
       "      <th>v07</th>\n",
       "      <th>h08</th>\n",
       "      <th>v08</th>\n",
       "      <th>h09</th>\n",
       "      <th>v09</th>\n",
       "      <th>h10</th>\n",
       "      <th>v10</th>\n",
       "      <th>h11</th>\n",
       "      <th>v11</th>\n",
       "      <th>h12</th>\n",
       "      <th>v12</th>\n",
       "      <th>h13</th>\n",
       "      <th>v13</th>\n",
       "      <th>h14</th>\n",
       "      <th>v14</th>\n",
       "      <th>h15</th>\n",
       "      <th>v15</th>\n",
       "      <th>h16</th>\n",
       "      <th>v16</th>\n",
       "      <th>h17</th>\n",
       "      <th>v17</th>\n",
       "      <th>h18</th>\n",
       "      <th>v18</th>\n",
       "      <th>h19</th>\n",
       "      <th>v19</th>\n",
       "      <th>h20</th>\n",
       "      <th>v20</th>\n",
       "      <th>h21</th>\n",
       "      <th>v21</th>\n",
       "      <th>h22</th>\n",
       "      <th>v22</th>\n",
       "      <th>h23</th>\n",
       "      <th>v23</th>\n",
       "      <th>h24</th>\n",
       "      <th>v24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28102001_1_38</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>3.0</td>\n",
       "      <td>T</td>\n",
       "      <td>3.0</td>\n",
       "      <td>T</td>\n",
       "      <td>3.0</td>\n",
       "      <td>T</td>\n",
       "      <td>3.0</td>\n",
       "      <td>T</td>\n",
       "      <td>3.0</td>\n",
       "      <td>T</td>\n",
       "      <td>3.0</td>\n",
       "      <td>T</td>\n",
       "      <td>3.0</td>\n",
       "      <td>T</td>\n",
       "      <td>3.0</td>\n",
       "      <td>T</td>\n",
       "      <td>3.0</td>\n",
       "      <td>T</td>\n",
       "      <td>3.0</td>\n",
       "      <td>T</td>\n",
       "      <td>3.0</td>\n",
       "      <td>T</td>\n",
       "      <td>3.0</td>\n",
       "      <td>T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   provincia  municipio  estacion  magnitud punto_muestreo   ano  mes  dia  \\\n",
       "0         28        102         1         1  28102001_1_38  2022    1   30   \n",
       "\n",
       "   h01 v01  h02 v02  h03 v03  h04 v04  h05 v05  h06 v06  h07 v07  h08 v08  \\\n",
       "0  3.0   T  3.0   T  3.0   T  3.0   T  3.0   T  3.0   T  3.0   T  3.0   T   \n",
       "\n",
       "   h09 v09  h10 v10  h11 v11  h12 v12  h13 v13  h14 v14  h15 v15  h16 v16  \\\n",
       "0  3.0   T  3.0   T  3.0   T  3.0   T  NaN   N  NaN   N  NaN   N  NaN   N   \n",
       "\n",
       "   h17 v17  h18 v18  h19 v19  h20 v20  h21 v21  h22 v22  h23 v23  h24 v24  \n",
       "0  NaN   N  NaN   N  NaN   N  NaN   N  NaN   N  NaN   N  NaN   N  NaN   N  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aire = pd.read_csv(\"../Datos/Pandas/aire.csv\", sep = \";\")\n",
    "df_aire.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pd.read_excel()`\n",
    "\n",
    "La sintaxis básica de `pd.read_excel` es la siguiente:\n",
    "\n",
    "```python\n",
    "pd.read_excel(ruta_al_fichero, sheet_name=0, header=0, names=None, index_col=None, dtype=None)\n",
    "```\n",
    "\n",
    "Donde:\n",
    "- `ruta_al_fichero`:  Es el nombre del archivo o la ruta de Excel que queremos leer. \n",
    "\n",
    "- `sheet_name` (opcional): Indica la hoja o hojas del archivo Excel que queremos leer. Puede tener los siguientes valores:\n",
    "\n",
    "  - Un número *integer* que especifica el índice de la hoja (por ejemplo, `sheet_name=0` para la primera hoja).\n",
    "\n",
    "  - Un nombre de hoja como una cadena (por ejemplo, `sheet_name='Sheet1'`).\n",
    "\n",
    "  - Una lista de nombres de hojas para leer varias hojas (por ejemplo, `sheet_name=['Sheet1', 'Sheet2']`).\n",
    "\n",
    "- `header` (opcional): Indica la fila del archivo Excel que se utilizará como encabezado de columnas. Puede tener los siguientes valores:\n",
    "\n",
    "  - `None`: No hay encabezado y los datos se leerán sin nombres de columna.\n",
    "\n",
    "  - Un número *integer* que especifica la fila del archivo que se utilizará como encabezado de columna (por ejemplo, `header=0`).\n",
    "\n",
    "- `names` (opcional): Es una lista opcional de nombres para las columnas. Si se proporciona, reemplazará los nombres inferidos o los nombres de columna del archivo.\n",
    "\n",
    "- `index_col` (opcional): Especifica la columna (o columnas) que se utilizará como índice del DataFrame resultante. Puede ser un número *integer*, una cadena con el nombre de la columna o una lista de columnas.\n",
    "\n",
    "- `dtype` (opcional): Permite especificar el tipo de datos de las columnas. Puede ser un diccionario que mapee nombres de columna a tipos de datos o un solo tipo de datos para aplicar a todas las columnas.\n",
    "\n",
    "Además de estos parámetros, `pd.read_excel` también admite otros parámetros opcionales, como `skiprows`, `na_values`, `usecols` y más. Estos parámetros nos permiten personalizar aún más la lectura de archivos Excel según tus necesidades. Al igual que en el método `pd.read_csv()`, podemos  consultar la [documentación oficial](https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html) para obtener información más detallada sobre estos parámetros y sus opciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Datos/Pandas/espacios_protegidos.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_xlsx \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../Datos/Pandas/espacios_protegidos.xlsx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m df_xlsx\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\excel\\_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    494\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 495\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\excel\\_base.py:1550\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   1548\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1549\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1550\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m   1552\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1554\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1555\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1556\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1557\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\excel\\_base.py:1402\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1400\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[1;32m-> 1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1404\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m   1405\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   1406\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Datos/Pandas/espacios_protegidos.xlsx'"
     ]
    }
   ],
   "source": [
    "df_xlsx = pd.read_excel(\"../Datos/Pandas/espacios_protegidos.xlsx\", sheet_name=0)\n",
    "df_xlsx.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🚨⚠️ **NOTA** Puede que al ejecutar este línea de código os salga el siguiente error: \n",
    "\n",
    "![error](imagenes/error_excel.png)\n",
    "\n",
    "**DON'T PANIC!!!** Lo único que tendremos que hacer es importaros `openpyxl`. ¿Cómo? Nos vamos a la terminal y ejecutamos el siguiente código: \n",
    "\n",
    "```bash \n",
    "pip3 install openpyxl\n",
    "\n",
    "pip install openpyxl\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>espacio_prot_categoria</th>\n",
       "      <th>espacio_prot_figura</th>\n",
       "      <th>espacio_prot_nombre</th>\n",
       "      <th>espacio_prot_superficie_ha</th>\n",
       "      <th>espacio_prot_fecha_declaracion</th>\n",
       "      <th>espacio_prot_normativa</th>\n",
       "      <th>espacio_prot_informacion_web</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Áreas protegidas por instrumentos internacionales</td>\n",
       "      <td>Reserva de la Biosfera</td>\n",
       "      <td>Cuencas Altas de los ríos Manzanares, Lozoya y...</td>\n",
       "      <td>105655.000</td>\n",
       "      <td>1992-11-09</td>\n",
       "      <td>Normativa Áreas protegidas por instrumentos in...</td>\n",
       "      <td>Reserva de la Biosfera Cuencas Altas de los rí...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Áreas protegidas por instrumentos internacionales</td>\n",
       "      <td>Reserva de la Biosfera</td>\n",
       "      <td>Sierra del Rincón</td>\n",
       "      <td>15231.000</td>\n",
       "      <td>2005-06-29</td>\n",
       "      <td>Normativa Áreas protegidas por instrumentos in...</td>\n",
       "      <td>Reserva de la Biosfera Sierra del Rincón</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Áreas protegidas por instrumentos internacionales</td>\n",
       "      <td>Humedal de Importancia Internacional (RAMSAR)</td>\n",
       "      <td>Humedales del Macizo de Peñalara</td>\n",
       "      <td>487.198</td>\n",
       "      <td>2005-12-16</td>\n",
       "      <td>Normativa Áreas protegidas por instrumentos in...</td>\n",
       "      <td>Humedales Ramsar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Espacios Protegidos Red Natura 2000</td>\n",
       "      <td>Zona de Especial Protección para las Aves</td>\n",
       "      <td>Monte de El Pardo</td>\n",
       "      <td>15298.670</td>\n",
       "      <td>1988-02-01</td>\n",
       "      <td>Normativa Espacios Protegidos Red Natura 2000</td>\n",
       "      <td>Espacios protegidos Red Natura 2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Espacios Protegidos Red Natura 2000</td>\n",
       "      <td>Zona de Especial Protección para las Aves</td>\n",
       "      <td>Soto de Viñuelas</td>\n",
       "      <td>3071.890</td>\n",
       "      <td>1988-02-01</td>\n",
       "      <td>Normativa Espacios Protegidos Red Natura 2000</td>\n",
       "      <td>Espacios protegidos Red Natura 2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              espacio_prot_categoria  \\\n",
       "0  Áreas protegidas por instrumentos internacionales   \n",
       "1  Áreas protegidas por instrumentos internacionales   \n",
       "2  Áreas protegidas por instrumentos internacionales   \n",
       "3                Espacios Protegidos Red Natura 2000   \n",
       "4                Espacios Protegidos Red Natura 2000   \n",
       "\n",
       "                             espacio_prot_figura  \\\n",
       "0                         Reserva de la Biosfera   \n",
       "1                         Reserva de la Biosfera   \n",
       "2  Humedal de Importancia Internacional (RAMSAR)   \n",
       "3      Zona de Especial Protección para las Aves   \n",
       "4      Zona de Especial Protección para las Aves   \n",
       "\n",
       "                                 espacio_prot_nombre  \\\n",
       "0  Cuencas Altas de los ríos Manzanares, Lozoya y...   \n",
       "1                                  Sierra del Rincón   \n",
       "2                  Humedales del Macizo de Peñalara    \n",
       "3                                  Monte de El Pardo   \n",
       "4                                   Soto de Viñuelas   \n",
       "\n",
       "   espacio_prot_superficie_ha espacio_prot_fecha_declaracion  \\\n",
       "0                  105655.000                     1992-11-09   \n",
       "1                   15231.000                     2005-06-29   \n",
       "2                     487.198                     2005-12-16   \n",
       "3                   15298.670                     1988-02-01   \n",
       "4                    3071.890                     1988-02-01   \n",
       "\n",
       "                              espacio_prot_normativa  \\\n",
       "0  Normativa Áreas protegidas por instrumentos in...   \n",
       "1  Normativa Áreas protegidas por instrumentos in...   \n",
       "2  Normativa Áreas protegidas por instrumentos in...   \n",
       "3      Normativa Espacios Protegidos Red Natura 2000   \n",
       "4      Normativa Espacios Protegidos Red Natura 2000   \n",
       "\n",
       "                        espacio_prot_informacion_web  \n",
       "0  Reserva de la Biosfera Cuencas Altas de los rí...  \n",
       "1           Reserva de la Biosfera Sierra del Rincón  \n",
       "2                                   Humedales Ramsar  \n",
       "3                Espacios protegidos Red Natura 2000  \n",
       "4                Espacios protegidos Red Natura 2000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# volvemos a ejecutar el código para abrir el fichero\n",
    "df_xlsx = pd.read_excel(\"../Datos/Pandas/espacios_protegidos.xlsx\", sheet_name=0)\n",
    "df_xlsx.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pd.read_json()`\n",
    "\n",
    "Nos va a permitir abrir arcivos de tipo json. La sintaxis básica de `pd.read_json` es la siguiente:\n",
    "\n",
    "```python\n",
    "pd.read_json(ruta_al_fichero, orient=None, typ='frame', dtype=True, convert_axes=True, convert_dates=True, keep_default_dates=True, numpy=False, precise_float=False, date_unit=None, encoding=None, lines=False)\n",
    "```\n",
    "\n",
    "Los parámetros que puede recibir este método son:\n",
    "\n",
    "- `ruta_al_fichero`: Es la ruta del archivo JSON que deseamos leer.\n",
    "\n",
    "- `orient` (opcional): Especifica la orientación del archivo JSON. Puede tener los siguientes valores:\n",
    "\n",
    "  - `'columns'` (por defecto): Se espera que el archivo JSON tenga un formato de columna.\n",
    "\n",
    "  - `'index'`: Se espera que el archivo JSON tenga un formato de índice.\n",
    "\n",
    "  - `'records'`: Se espera que el archivo JSON tenga un formato de registros.\n",
    "\n",
    "  - `'split'`: Se espera que el archivo JSON tenga un formato dividido.\n",
    "\n",
    "  - `'values'`: Se espera que el archivo JSON contenga solo valores sin ninguna etiqueta de columna o índice.\n",
    "\n",
    "- `typ` (opcional): Indica el tipo de objeto a crear. Puede tener los siguientes valores:\n",
    "\n",
    "  - `'frame'` (por defecto): Crea un objeto DataFrame.\n",
    "\n",
    "  - `'series'`: Crea un objeto Series.\n",
    "\n",
    "- `dtype` (opcional): Permite especificar el tipo de datos de las columnas. Puede ser un diccionario que mapee nombres de columna a tipos de datos o un solo tipo de datos para aplicar a todas las columnas.\n",
    "\n",
    "- `convert_axes` (opcional): Indica si las etiquetas de los ejes deben convertirse en índices o nombres de columna. Por defecto, es `True`.\n",
    "\n",
    "- `convert_dates` (opcional): Indica si se deben convertir las cadenas de fecha y hora en objetos de fecha y hora. Por defecto, es `True`.\n",
    "\n",
    "- `keep_default_dates` (opcional): Especifica si se deben mantener las fechas predeterminadas al convertir cadenas de fecha y hora. Por defecto, es `True`.\n",
    "\n",
    "- `numpy` (opcional): Indica si los datos deben devolverse como una matriz NumPy en lugar de un objeto DataFrame. Por defecto, es `False`.\n",
    "\n",
    "- `precise_float` (opcional): Indica si se deben utilizar números de punto *float* precisos en lugar de valores de punto *float* nativos de Python. Por defecto, es `False`.\n",
    "\n",
    "- `date_unit` (opcional): Especifica la unidad de fecha y hora si se deben convertir las cadenas de fecha y hora. Puede ser `'s'` para segundos o `'ms'` para milisegundos.\n",
    "\n",
    "- `encoding` (opcional): Permite especificar la codificación del archivo JSON si no se puede inferir automáticamente.\n",
    "\n",
    "- `lines` (opcional): Indica si el archivo JSON contiene múltiples objetos JSON en líneas separadas en lugar de un solo objeto JSON.\n",
    "\n",
    "Estos son solo algunos de los parámetros más comunes utilizados en `pd.read_json`. La función `pd.read_json` también admite otros parámetros opcionales, como `orient`, `date_format`, `numpy`, `compression` y más. Podemos consultar la [documentación oficial](https://pandas.pydata.org/docs/reference/api/pandas.read_json.html) para obtener información más detallada sobre estos parámetros y sus opciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'residuos_pelig_cantidad_ton': 23476.42, 'res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'residuos_pelig_cantidad_ton': 1927.25, 'resi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'residuos_pelig_cantidad_ton': 25333.54, 'res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'residuos_pelig_cantidad_ton': 22060.07, 'res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'residuos_pelig_cantidad_ton': 13109.74, 'res...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data\n",
       "0  {'residuos_pelig_cantidad_ton': 23476.42, 'res...\n",
       "1  {'residuos_pelig_cantidad_ton': 1927.25, 'resi...\n",
       "2  {'residuos_pelig_cantidad_ton': 25333.54, 'res...\n",
       "3  {'residuos_pelig_cantidad_ton': 22060.07, 'res...\n",
       "4  {'residuos_pelig_cantidad_ton': 13109.74, 'res..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_residuos = pd.read_json(\"../Datos/Pandas/residuos.json\")\n",
    "df_residuos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>residuos_pelig_cantidad_ton</th>\n",
       "      <th>residuos_pelig_año</th>\n",
       "      <th>residuos_pelig_opcion_gestion</th>\n",
       "      <th>residuos_pelig_tratamiento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23476.42</td>\n",
       "      <td>2012</td>\n",
       "      <td>Reciclado</td>\n",
       "      <td>Recuperación de disolventes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1927.25</td>\n",
       "      <td>2012</td>\n",
       "      <td>Reciclado</td>\n",
       "      <td>Recuperación de metales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25333.54</td>\n",
       "      <td>2012</td>\n",
       "      <td>Reciclado</td>\n",
       "      <td>Regeneración de aceite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22060.07</td>\n",
       "      <td>2012</td>\n",
       "      <td>Tratamiento previo a otras formas de valorización</td>\n",
       "      <td>Trituración previa a valorización de baterías</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13109.74</td>\n",
       "      <td>2012</td>\n",
       "      <td>Tratamiento previo a otras formas de valorización</td>\n",
       "      <td>Operaciones previas a valorización de RAEE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   residuos_pelig_cantidad_ton  residuos_pelig_año  \\\n",
       "0                     23476.42                2012   \n",
       "1                      1927.25                2012   \n",
       "2                     25333.54                2012   \n",
       "3                     22060.07                2012   \n",
       "4                     13109.74                2012   \n",
       "\n",
       "                       residuos_pelig_opcion_gestion  \\\n",
       "0                                          Reciclado   \n",
       "1                                          Reciclado   \n",
       "2                                          Reciclado   \n",
       "3  Tratamiento previo a otras formas de valorización   \n",
       "4  Tratamiento previo a otras formas de valorización   \n",
       "\n",
       "                      residuos_pelig_tratamiento  \n",
       "0                    Recuperación de disolventes  \n",
       "1                        Recuperación de metales  \n",
       "2                         Regeneración de aceite  \n",
       "3  Trituración previa a valorización de baterías  \n",
       "4     Operaciones previas a valorización de RAEE  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# esto nos devuelve un DataFrame que esta lleno de diccionarios!\n",
    "# sin embargo, lo podemos convertir fácilmente a algo más legible usando la siguiente sintaxis\n",
    "\n",
    "df_residuos2 = df_residuos['data'].apply(pd.Series)\n",
    "df_residuos2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pd.read_pickle`\n",
    "\n",
    "\n",
    "**¿Qué es Pickle exactamente?**\n",
    "\n",
    "Un archivo de tipo pickle es un archivo binario en Python que se utiliza para serializar y deserializar objetos,  su acrónimo viene de *Python Pickle Format* que fue desarrollado exclusivamente para Python. Leyendo solo esto podemos seguir sin tener claro que es un archivo de tipo pickle. Expliquemoslo de una forma más sencilla. Imagina que tienes un montón de objetos especiales en tu habitación, como juguetes, libros, peluches, etc. Ahora, supongamos que quieres guardar todos estos objetos en una caja para poder llevarlos contigo o almacenarlos de manera segura.\n",
    "\n",
    "Aquí es donde entra en juego un archivo pickle. Es como una caja especial que te permite guardar todos estos objetos en ella. Pero, en lugar de objetos físicos, el archivo pickle puede almacenar objetos digitales, como datos, números, listas, diccionarios y más.\n",
    "\n",
    "El archivo pickle es como una caja mágica que puede guardar todos tus objetos digitales de Python. Cuando guardas estos objetos en un archivo pickle, se convierten en una forma especial que se puede almacenar en tu computadora o enviar a alguien más.\n",
    "\n",
    "La sintaxis básica de `pd.read_pickle` es la siguiente:\n",
    "\n",
    "```python\n",
    "pd.read_pickle(ruta_al_fichero, compression='infer')\n",
    "```\n",
    "\n",
    "Donde:\n",
    "\n",
    "- `filepath_or_buffer`: Es la ruta del archivo pickle que deseas leer.\n",
    "\n",
    "- `compression` (opcional): Es un parámetro opcional que indica el tipo de compresión utilizado en el archivo pickle. Por defecto, es `'infer'`, lo que significa que la biblioteca intentará inferir automáticamente el tipo de compresión. Puedes especificar un tipo de compresión explícitamente, como `'gzip'` o `'bz2'`, si el archivo pickle está comprimido.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Colombia': 'Bogotá', 'Ecuador': 'Quito', 'Argentina': 'Buenos'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pkl = pd.read_pickle(\"../Datos/Pandas/paises_capitales.pkl\")\n",
    "df_pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexación en Pandas (`loc` e `iloc`)\n",
    "\n",
    "En Pandas, tanto `loc` como `iloc` son métodos para acceder y manipular datos en un **DataFrame**. Ambos métodos ofrecen formas de indexar datos, ya sea utilizando etiquetas o números, respectivamente.\n",
    "\n",
    "- `loc`: Este método se utiliza para acceder a los datos utilizando etiquetas de fila y columna. Con `loc`, podemos seleccionar filas y columnas **utilizando sus nombres o etiquetas**. La sintaxis general para `loc` es `df.loc[nombre_filas, nombre_columnas]`, donde `filas` y `columnas` pueden ser un único nombre o una lista de nombres.\n",
    "\n",
    "- `iloc`: Se utiliza para acceder a los datos utilizando índices de filas y columnas. Con `iloc`, podemos seleccionar filas y columnas **basándonos en sus posiciones numéricas**. La sintaxis general para `iloc` es `df.iloc[índice_filas, índice_columnas]`, donde `filas` y `columnas` pueden ser un único número(índice) o una lista de números(índices).\n",
    "\n",
    "La principal diferencia entre `loc` y `iloc` radica en cómo se realizan las selecciones:\n",
    "\n",
    "- `loc`: Utiliza etiquetas o nombres de filas y columnas para indexar los datos. Por ejemplo, `df.loc[3, 'A']` seleccionará el valor en la fila con etiqueta 3 y la columna con etiqueta 'A'.\n",
    "\n",
    "- `iloc`: Por otro lado, `iloc` utiliza índices basados en la posición para realizar las selecciones. Por ejemplo, `df.iloc[3, 0]` seleccionará el valor en la cuarta fila y primera columna (recordemos que los índices empiezan en 0).\n",
    "\n",
    "Además, debemos tener en cuenta que `loc` incluye el límite superior en los rangos de selección, mientras que `iloc` lo excluye. Por ejemplo, `df.loc[1:3, 'A']` seleccionará las filas con etiquetas 1, 2 y 3, mientras que `df.iloc[1:3, 0]` seleccionará las filas con índices 1 y 2 (excluyendo el índice 3).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Oro</th>\n",
       "      <th>Plata</th>\n",
       "      <th>Bronce</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>País</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>China</th>\n",
       "      <td>1473</td>\n",
       "      <td>994</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Japón</th>\n",
       "      <td>1032</td>\n",
       "      <td>1037</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corea del Sur</th>\n",
       "      <td>745</td>\n",
       "      <td>663</td>\n",
       "      <td>827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Irán</th>\n",
       "      <td>179</td>\n",
       "      <td>181</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kazajistán</th>\n",
       "      <td>155</td>\n",
       "      <td>158</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>India</th>\n",
       "      <td>154</td>\n",
       "      <td>202</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tailandia</th>\n",
       "      <td>132</td>\n",
       "      <td>175</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indonesia</th>\n",
       "      <td>112</td>\n",
       "      <td>131</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>China Taipéi</th>\n",
       "      <td>99</td>\n",
       "      <td>144</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corea del Norte</th>\n",
       "      <td>91</td>\n",
       "      <td>120</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Oro  Plata  Bronce\n",
       "País                                \n",
       "China            1473    994     720\n",
       "Japón            1032   1037     985\n",
       "Corea del Sur     745    663     827\n",
       "Irán              179    181     197\n",
       "Kazajistán        155    158     224\n",
       "India             154    202     315\n",
       "Tailandia         132    175     278\n",
       "Indonesia         112    131     240\n",
       "China Taipéi       99    144     276\n",
       "Corea del Norte    91    120     235"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importamos un nuevo fichero de datos para entender mejor estos conceptos\n",
    "df = pd.read_csv(\"../Datos/Pandas/medallas.csv\",index_col=[\"País\"],  usecols=[\"Oro\",\"Plata\", \"Bronce\", \"País\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección a través de un único elemento\n",
    "\n",
    "Vamos a intentar sacar el valor de 1037, en concreto hace referencia a las medallas de Plata de Japón. Recordemos que: \n",
    "\n",
    "- En el `loc` usaremos los nombres de las filas y las columnas (es como el juego de hundir la flota), corresponde a lo que tenemos en rojo en la imagen. \n",
    "\n",
    "- En el `iloc` usaremos los indices de las filas y las columnas, igual que hacíamos en las listas o los **array*s* de NumPy, corresponde con lo que vemos en verde en la imagen. \n",
    "\n",
    "![imagen](https://github.com/Hack-io-Data/Imagenes/blob/main/02-Imagenes/Pandas/dataframe_medallas_plata_japon.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El número de medallas de Plata conseguidas por Japón usando el LOC son:  1037\n",
      "El número de medallas de Plata conseguidas por Japón usando el ILOC es:  1037\n"
     ]
    }
   ],
   "source": [
    "# Usando el loc, accediendo por los nombres de las filas y las columnas\n",
    "print(f'El número de medallas de Plata conseguidas por Japón usando el LOC son:  {df.loc[\"Japón\", \"Plata\"]}')\n",
    "\n",
    "# usando el iloc, accediendo por los índices, que empiezan en 0 como siempre en Python\n",
    "print(f'El número de medallas de Plata conseguidas por Japón usando el ILOC es:  {df.iloc[1, 1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imaginemos que queremos sacar una fila en concreto pero todas las columnas o viceversa:\n",
    "\n",
    "> En estos casos tendremos que usar `:`, esto índica que lo queremos todo. Es decir: \n",
    "\n",
    "```python\n",
    "[filas_deseadas, :] # le estamos diciendo que nos busque por una fila dada y nos devuelva todas las columnas\n",
    "\n",
    "[:, columna_deseada] # devuelvenos todas las filas de la columna que especifiquemos\n",
    "```\n",
    "\n",
    "Imaginemos ahora que queremos extraer toda la información de Japón. En este caso, querremos de una fila concreta y todas las columnas. \n",
    "\n",
    "![imagen2](https://github.com/Hack-io-Data/Imagenes/blob/main/02-Imagenes/Pandas/dataframe_medallas_plata_japon.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El número de medallas conseguidas por Japón  usando el LOC es: \n",
      "  Oro       1032\n",
      "Plata     1037\n",
      "Bronce     985\n",
      "Name: Japón, dtype: int64\n",
      "\n",
      "----------------------\n",
      "\n",
      "El número de medallas conseguidas por Japón usando el ILOC es: \n",
      "  Oro       1032\n",
      "Plata     1037\n",
      "Bronce     985\n",
      "Name: Japón, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Usando el loc, accediendo por los nombres de las filas y las columnas\n",
    "print(f'El número de medallas conseguidas por Japón  usando el LOC es: \\n  {df.loc[\"Japón\", :]}')\n",
    "\n",
    "print(\"\\n----------------------\\n\")\n",
    "# Usando el iloc, accediendo por los índices\n",
    "print(f'El número de medallas conseguidas por Japón usando el ILOC es: \\n  {df.iloc[1, :]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Y si ahora quisieramos extraer todas las medallas de Oro para todos los países? En este caso querríamos todas las filas y una sola columna. \n",
    "\n",
    "![imagen3](https://github.com/Hack-io-Data/Imagenes/blob/main/02-Imagenes/Pandas/dataframe_medallas_oro.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El número de medalas de Oro de todos los países usando el LOC es: \n",
      "  País\n",
      "China              1473\n",
      "Japón              1032\n",
      "Corea del Sur       745\n",
      "Irán                179\n",
      "Kazajistán          155\n",
      "India               154\n",
      "Tailandia           132\n",
      "Indonesia           112\n",
      "China Taipéi         99\n",
      "Corea del Norte      91\n",
      "Name: Oro, dtype: int64\n",
      "\n",
      "----------------------\n",
      "\n",
      "El número de medalas de Oro de todos los países usando el ILOC es: \n",
      "  País\n",
      "China              1473\n",
      "Japón              1032\n",
      "Corea del Sur       745\n",
      "Irán                179\n",
      "Kazajistán          155\n",
      "India               154\n",
      "Tailandia           132\n",
      "Indonesia           112\n",
      "China Taipéi         99\n",
      "Corea del Norte      91\n",
      "Name: Oro, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Usando el loc, accediendo por los nombres de las filas y las columnas\n",
    "print(f'El número de medalas de Oro de todos los países usando el LOC es: \\n  {df.loc[:, \"Oro\"]}')\n",
    "\n",
    "print(\"\\n----------------------\\n\")\n",
    "# Usando el iloc, accediendo por los índices\n",
    "print(f'El número de medalas de Oro de todos los países usando el ILOC es: \\n  {df.iloc[:, 0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección a través de una lista de valores \n",
    "\n",
    "En este caso la sintaxis del `loc` y el `iloc` cambian un poco. Seguiremos usando los nombres de las filas y las columnas para el `loc` y los índices para el `iloc`, pero tendremos que añadir un corchete más. \n",
    "\n",
    "```python\n",
    "[[fila_deseada1, fila_deseada2], :] # le estamos diciendo que nos busque por una fila dada y nos devuelva todas las columnas. FIJAOS COMO LO QUE HEMOS HECHO HA SIDO AÑADIR UNOS CORCHETES MÁS DONDE INCLUIREMOS LOS NOMBRES DE LAS FILAS O COLUMNAS QUE QUERRAMOS SEPARADAS POR COMAS. Los ':' siguen indicando que queremo todas las columnas en este caso.\n",
    "\n",
    "[:, [col_deseada1, col_deseada2]] # devuelvenos todas las filas de la columna que especifiquemos. FIJAOS COMO LO QUE HEMOS HECHO HA SIDO AÑADIR UNOS CORCHETES MÁS DONDE INCLUIREMOS LOS NOMBRES DE LAS FILAS O COLUMNAS QUE QUERRAMOS SEPARADAS POR COMAS. Los ':' siguen indicando que queremos todas las filas.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a querer extraer la información de las medallas de Oro, pero solo vamos a querer los datos de Corea (Corea del Sur y Corea del Norte). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Oro</th>\n",
       "      <th>Plata</th>\n",
       "      <th>Bronce</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>País</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>China</th>\n",
       "      <td>1473</td>\n",
       "      <td>994</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Japón</th>\n",
       "      <td>1032</td>\n",
       "      <td>1037</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corea del Sur</th>\n",
       "      <td>745</td>\n",
       "      <td>663</td>\n",
       "      <td>827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Irán</th>\n",
       "      <td>179</td>\n",
       "      <td>181</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kazajistán</th>\n",
       "      <td>155</td>\n",
       "      <td>158</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>India</th>\n",
       "      <td>154</td>\n",
       "      <td>202</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tailandia</th>\n",
       "      <td>132</td>\n",
       "      <td>175</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indonesia</th>\n",
       "      <td>112</td>\n",
       "      <td>131</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>China Taipéi</th>\n",
       "      <td>99</td>\n",
       "      <td>144</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corea del Norte</th>\n",
       "      <td>91</td>\n",
       "      <td>120</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Oro  Plata  Bronce\n",
       "País                                \n",
       "China            1473    994     720\n",
       "Japón            1032   1037     985\n",
       "Corea del Sur     745    663     827\n",
       "Irán              179    181     197\n",
       "Kazajistán        155    158     224\n",
       "India             154    202     315\n",
       "Tailandia         132    175     278\n",
       "Indonesia         112    131     240\n",
       "China Taipéi       99    144     276\n",
       "Corea del Norte    91    120     235"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las medallas de Oro para Corea del Norte y del Sur usando el LOC es: \n",
      "  País\n",
      "Corea del Sur      745\n",
      "Corea del Norte     91\n",
      "Name: Oro, dtype: int64\n",
      "\n",
      "----------------------\n",
      "\n",
      "Las medallas de Oro para Corea del Norte y del Sur usando el ILOC es: \n",
      "  País\n",
      "Corea del Sur      745\n",
      "Corea del Norte     91\n",
      "Name: Oro, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Usando el loc, accediendo por los nombres de las filas y las columnas\n",
    "print(f'Las medallas de Oro para Corea del Norte y del Sur usando el LOC es: \\n  {df.loc[[\"Corea del Sur\", \"Corea del Norte\"], \"Oro\"]}')\n",
    "\n",
    "print(\"\\n----------------------\\n\")\n",
    "# Usando el iloc, accediendo por los índices\n",
    "print(f'Las medallas de Oro para Corea del Norte y del Sur usando el ILOC es: \\n  {df.iloc[[2, -1], 0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imaginemos ahora que no queremos solo la información de las medallas de Oro para Corea del Norte y del Sur, si no que también queremos la información de las medallas de Plata. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las medallas de Oro y Plata para Corea del Norte y del Sur usando el LOC es: \n",
      "                   Oro  Plata\n",
      "País                       \n",
      "Corea del Sur    745    663\n",
      "Corea del Norte   91    120\n",
      "\n",
      "----------------------\n",
      "\n",
      "Las medallas de Oro y Plata para Corea del Norte y del Sur usando el ILOC es: \n",
      "                   Oro  Plata\n",
      "País                       \n",
      "Corea del Sur    745    663\n",
      "Corea del Norte   91    120\n"
     ]
    }
   ],
   "source": [
    "# Usando el loc, accediendo por los nombres de las filas y las columnas\n",
    "print(f'Las medallas de Oro y Plata para Corea del Norte y del Sur usando el LOC es: \\n  {df.loc[[\"Corea del Sur\", \"Corea del Norte\"], [\"Oro\", \"Plata\"]]}')\n",
    "\n",
    "print(\"\\n----------------------\\n\")\n",
    "# Usando el iloc, accediendo por los índices\n",
    "print(f'Las medallas de Oro y Plata para Corea del Norte y del Sur usando el ILOC es: \\n  {df.iloc[[2, -1], [0,1]]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de un rango de datos a través de un corte\n",
    "\n",
    "En este caso podremos usar la sintaxis de `[start:stop:step]` que conocemos de listas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Oro</th>\n",
       "      <th>Plata</th>\n",
       "      <th>Bronce</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>País</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>China</th>\n",
       "      <td>1473</td>\n",
       "      <td>994</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Japón</th>\n",
       "      <td>1032</td>\n",
       "      <td>1037</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corea del Sur</th>\n",
       "      <td>745</td>\n",
       "      <td>663</td>\n",
       "      <td>827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Irán</th>\n",
       "      <td>179</td>\n",
       "      <td>181</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kazajistán</th>\n",
       "      <td>155</td>\n",
       "      <td>158</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>India</th>\n",
       "      <td>154</td>\n",
       "      <td>202</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tailandia</th>\n",
       "      <td>132</td>\n",
       "      <td>175</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indonesia</th>\n",
       "      <td>112</td>\n",
       "      <td>131</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>China Taipéi</th>\n",
       "      <td>99</td>\n",
       "      <td>144</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corea del Norte</th>\n",
       "      <td>91</td>\n",
       "      <td>120</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Oro  Plata  Bronce\n",
       "País                                \n",
       "China            1473    994     720\n",
       "Japón            1032   1037     985\n",
       "Corea del Sur     745    663     827\n",
       "Irán              179    181     197\n",
       "Kazajistán        155    158     224\n",
       "India             154    202     315\n",
       "Tailandia         132    175     278\n",
       "Indonesia         112    131     240\n",
       "China Taipéi       99    144     276\n",
       "Corea del Norte    91    120     235"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lo primero que vamos a hacer es recordar el DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejercicio vamos a querer sacar las medallas de Oro y Bronce desde la Irán hasta Indonesia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las medallas de Oro y Bronce de Irán hasta Indonesia usando el LOC son: \n",
      "              Oro  Bronce\n",
      "País                   \n",
      "Irán        179     197\n",
      "Kazajistán  155     224\n",
      "India       154     315\n",
      "Tailandia   132     278\n",
      "Indonesia   112     240\n",
      "\n",
      "----------------------\n",
      "\n",
      "Las medallas de Oro y Bronce de Irán hasta Indonesia usando el ILOC son: \n",
      "              Oro  Bronce\n",
      "País                   \n",
      "Irán        179     197\n",
      "Kazajistán  155     224\n",
      "India       154     315\n",
      "Tailandia   132     278\n",
      "Indonesia   112     240\n"
     ]
    }
   ],
   "source": [
    "# Usando el loc, accediendo por los nombres de las filas y las columnas\n",
    "print(f\"Las medallas de Oro y Bronce de Irán hasta Indonesia usando el LOC son: \\n  {df.loc['Irán': 'Indonesia', [\"Oro\", \"Bronce\"] ]}\")\n",
    "\n",
    "print(\"\\n----------------------\\n\")\n",
    "# Usando el iloc, accediendo por los índices\n",
    "print(f'Las medallas de Oro y Bronce de Irán hasta Indonesia usando el ILOC son: \\n  {df.iloc[3:8, [0,2]]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Y si quisieramos saber todas las medallas de China, Corea del Sur, Kazajistán y Tailandia? En este caso tendremos que hacer uso del `[start_ stop: step]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Oro</th>\n",
       "      <th>Plata</th>\n",
       "      <th>Bronce</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>País</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>China</th>\n",
       "      <td>1473</td>\n",
       "      <td>994</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Japón</th>\n",
       "      <td>1032</td>\n",
       "      <td>1037</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corea del Sur</th>\n",
       "      <td>745</td>\n",
       "      <td>663</td>\n",
       "      <td>827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Irán</th>\n",
       "      <td>179</td>\n",
       "      <td>181</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kazajistán</th>\n",
       "      <td>155</td>\n",
       "      <td>158</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>India</th>\n",
       "      <td>154</td>\n",
       "      <td>202</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tailandia</th>\n",
       "      <td>132</td>\n",
       "      <td>175</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indonesia</th>\n",
       "      <td>112</td>\n",
       "      <td>131</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>China Taipéi</th>\n",
       "      <td>99</td>\n",
       "      <td>144</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corea del Norte</th>\n",
       "      <td>91</td>\n",
       "      <td>120</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Oro  Plata  Bronce\n",
       "País                                \n",
       "China            1473    994     720\n",
       "Japón            1032   1037     985\n",
       "Corea del Sur     745    663     827\n",
       "Irán              179    181     197\n",
       "Kazajistán        155    158     224\n",
       "India             154    202     315\n",
       "Tailandia         132    175     278\n",
       "Indonesia         112    131     240\n",
       "China Taipéi       99    144     276\n",
       "Corea del Norte    91    120     235"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todas las medallas para China, Corea del Sur,  Kazajistán y Tailandia usando el LOC es: \n",
      "                  Oro  Plata  Bronce\n",
      "País                              \n",
      "China          1473    994     720\n",
      "Corea del Sur   745    663     827\n",
      "Kazajistán      155    158     224\n",
      "Tailandia       132    175     278\n",
      "\n",
      "----------------------\n",
      "\n",
      "Todas las medallas para China, Corea del Sur,  Kazajistán y Tailandia usando el ILOC es: \n",
      "                  Oro  Plata  Bronce\n",
      "País                              \n",
      "China          1473    994     720\n",
      "Corea del Sur   745    663     827\n",
      "Kazajistán      155    158     224\n",
      "Tailandia       132    175     278\n"
     ]
    }
   ],
   "source": [
    "# Usando el loc, accediendo por los nombres de las filas y las columnas\n",
    "print(f\"Todas las medallas para China, Corea del Sur,  Kazajistán y Tailandia usando el LOC es: \\n  {df.loc[\"China\":\"Tailandia\":2, :]}\")\n",
    "\n",
    "print(\"\\n----------------------\\n\")\n",
    "# Usando el iloc, accediendo por los índices\n",
    "print(f'Todas las medallas para China, Corea del Sur,  Kazajistán y Tailandia usando el ILOC es: \\n  {df.iloc[:7:2, :]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleccionar basado en una condición \n",
    "\n",
    "Al igual que en NumPy podemos filtrar los datos de nuestro **DataFrame** usando operadores de comparación,  como `>`, `<`, `>=`, `<=`, `==` o `!=`. Pero antes de ponernos a ver como filtrar datos, aprendamos a acceder solo a una columna de nuestro **DataFrame**. Podríamos pensar que lo podemos hacer con un `loc` o un `iloc` como hemos estado viendo hasta ahora, pero hay una forma un poco más sencilla. Para eso deberemos seguir la siguiente sintaxis:\n",
    "\n",
    "```python\n",
    "df[\"nombre_columna\"]\n",
    "df.nombre_columna\n",
    "# estas dos opciones me devuelven exactamente lo mismo. \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Oro</th>\n",
       "      <th>Plata</th>\n",
       "      <th>Bronce</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>País</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>China</th>\n",
       "      <td>1473</td>\n",
       "      <td>994</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Japón</th>\n",
       "      <td>1032</td>\n",
       "      <td>1037</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corea del Sur</th>\n",
       "      <td>745</td>\n",
       "      <td>663</td>\n",
       "      <td>827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Irán</th>\n",
       "      <td>179</td>\n",
       "      <td>181</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kazajistán</th>\n",
       "      <td>155</td>\n",
       "      <td>158</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>India</th>\n",
       "      <td>154</td>\n",
       "      <td>202</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tailandia</th>\n",
       "      <td>132</td>\n",
       "      <td>175</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indonesia</th>\n",
       "      <td>112</td>\n",
       "      <td>131</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>China Taipéi</th>\n",
       "      <td>99</td>\n",
       "      <td>144</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corea del Norte</th>\n",
       "      <td>91</td>\n",
       "      <td>120</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Oro  Plata  Bronce\n",
       "País                                \n",
       "China            1473    994     720\n",
       "Japón            1032   1037     985\n",
       "Corea del Sur     745    663     827\n",
       "Irán              179    181     197\n",
       "Kazajistán        155    158     224\n",
       "India             154    202     315\n",
       "Tailandia         132    175     278\n",
       "Indonesia         112    131     240\n",
       "China Taipéi       99    144     276\n",
       "Corea del Norte    91    120     235"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recordamos el DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "País\n",
       "China              1473\n",
       "Japón              1032\n",
       "Corea del Sur       745\n",
       "Irán                179\n",
       "Kazajistán          155\n",
       "India               154\n",
       "Tailandia           132\n",
       "Indonesia           112\n",
       "China Taipéi         99\n",
       "Corea del Norte      91\n",
       "Name: Oro, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accedemos a los datos de la columna 'Oro'\n",
    "# Fijaos como nos ha devuelto una serie donde tenemos todos los valores de la columna 'Oro'\n",
    "df[\"Oro\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "País\n",
       "China              1473\n",
       "Japón              1032\n",
       "Corea del Sur       745\n",
       "Irán                179\n",
       "Kazajistán          155\n",
       "India               154\n",
       "Tailandia           132\n",
       "Indonesia           112\n",
       "China Taipéi         99\n",
       "Corea del Norte      91\n",
       "Name: Oro, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# El código de arriba es exactamente igual que:\n",
    "df.Oro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Y que pasaría si quisiera acceder a varias columnas? Solo podremos usar la sintaxis `df[[\"columna_1\", \"columna_2\"]]`. Fijaos como ahora estamos añadiendo un corchete extra a la sintaxis que hemos aprendido en los pasos anteriores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Oro</th>\n",
       "      <th>Bronce</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>País</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>China</th>\n",
       "      <td>1473</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Japón</th>\n",
       "      <td>1032</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corea del Sur</th>\n",
       "      <td>745</td>\n",
       "      <td>827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Irán</th>\n",
       "      <td>179</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kazajistán</th>\n",
       "      <td>155</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>India</th>\n",
       "      <td>154</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tailandia</th>\n",
       "      <td>132</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indonesia</th>\n",
       "      <td>112</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>China Taipéi</th>\n",
       "      <td>99</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corea del Norte</th>\n",
       "      <td>91</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Oro  Bronce\n",
       "País                         \n",
       "China            1473     720\n",
       "Japón            1032     985\n",
       "Corea del Sur     745     827\n",
       "Irán              179     197\n",
       "Kazajistán        155     224\n",
       "India             154     315\n",
       "Tailandia         132     278\n",
       "Indonesia         112     240\n",
       "China Taipéi       99     276\n",
       "Corea del Norte    91     235"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"Oro\", \"Bronce\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que hemos visto esto como acceder a los datos de una o varias columnas unicamente, vamos a ver como podemos filtrar los datos del **DataFrame**, igual que hacíamos en los *array*s. \n",
    "\n",
    "En este primer ejemplo, vamos a quedarnos con todos los datos donde las medallas de Oro  sean mayor que 1000. En este caso seguiremos la siguiente sintaxis: \n",
    "\n",
    "```python\n",
    "df.loc[df[\"columna\"] CONDICION]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El resultado usando la sintaxis de DF.COLUMNA usando LOC es:\n",
      "         Oro  Plata  Bronce\n",
      "País                      \n",
      "China  1473    994     720\n",
      "Japón  1032   1037     985\n",
      "\n",
      " --------------- \n",
      "\n",
      "El resultado usando la sintaxis de df['COLUMNA'] usando LOC es:\n",
      "         Oro  Plata  Bronce\n",
      "País                      \n",
      "China  1473    994     720\n",
      "Japón  1032   1037     985\n"
     ]
    }
   ],
   "source": [
    "# filtramos nuestros datos para quedarnos solo con las filas donde la temperatura sean mayor que 12\n",
    "df_mayor_1000_1 = df.loc[df.Oro > 1000, :]\n",
    "print(f\"El resultado usando la sintaxis de DF.COLUMNA usando LOC es:\\n {df_mayor_1000_1}\")\n",
    "\n",
    "print(\"\\n --------------- \\n\")\n",
    "\n",
    "# la linea de arriba es exactamente la misma que esta que vemos aquí abajo\n",
    "df_mayor_1000_2 = df.loc[df[\"Oro\"] > 1000, :]\n",
    "print(f\"El resultado usando la sintaxis de df['COLUMNA'] usando LOC es:\\n {df_mayor_1000_2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/Contenido/DataScience/lolo/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ¿y como lo haríamos con iloc? Se nos ocurriría que usando los corchetes, poniendo el índice de la columna que queremos usar como filtro. \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# veamoslo. \u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df\u001b[38;5;241m.\u001b[39miloc[\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1000\u001b[39m, :]\n",
      "File \u001b[0;32m~/Documents/Contenido/DataScience/lolo/lib/python3.12/site-packages/pandas/core/frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Documents/Contenido/DataScience/lolo/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# ¿y como lo haríamos con iloc? Se nos ocurriría que usando los corchetes, poniendo el índice de la columna que queremos usar como filtro. \n",
    "# veamoslo. \n",
    "df.iloc[df[0] > 1000, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⚠️ Obtenemos el error porque `iloc` no puede aceptar una Serie booleana. Sólo acepta una lista booleana. Podemos utilizar la función `list()` para convertir una Serie en una lista booleana. Por lo tanto, tendríamos que:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Oro</th>\n",
       "      <th>Plata</th>\n",
       "      <th>Bronce</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>País</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>China</th>\n",
       "      <td>1473</td>\n",
       "      <td>994</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Japón</th>\n",
       "      <td>1032</td>\n",
       "      <td>1037</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Oro  Plata  Bronce\n",
       "País                      \n",
       "China  1473    994     720\n",
       "Japón  1032   1037     985"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[list(df.Oro > 1000), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El resultado usando la sintaxis de DF.COLUMNA usando LOC es:\n",
      "         Oro  Plata  Bronce\n",
      "País                      \n",
      "China  1473    994     720\n",
      "Japón  1032   1037     985\n",
      "\n",
      " --------------- \n",
      "\n",
      "El resultado usando la sintaxis de df['COLUMNA'] usando LOC es:\n",
      "         Oro  Plata  Bronce\n",
      "País                      \n",
      "China  1473    994     720\n",
      "Japón  1032   1037     985\n",
      "\n",
      " --------------- \n",
      "\n",
      "El resultado usando la sintaxis de df['COLUMNA'] usando ILOC es:\n",
      "         Oro  Plata  Bronce\n",
      "País                      \n",
      "China  1473    994     720\n",
      "Japón  1032   1037     985\n"
     ]
    }
   ],
   "source": [
    "# si juntamos todo lo aprendido de loc e iloc en las últimas celdas\n",
    "\n",
    "# filtramos nuestros datos para quedarnos solo con las filas donde el número de medallas de Oro sea mayor que 1000\n",
    "df_mayor_1000_1 = df.loc[df.Oro > 1000, :]\n",
    "print(f\"El resultado usando la sintaxis de DF.COLUMNA usando LOC es:\\n {df_mayor_1000_1}\")\n",
    "\n",
    "print(\"\\n --------------- \\n\")\n",
    "\n",
    "# la linea de arriba es exactamente la misma que esta que vemos aquí abajo\n",
    "df_mayor_1000_2 = df.loc[df[\"Oro\"] > 1000, :]\n",
    "print(f\"El resultado usando la sintaxis de df['COLUMNA'] usando LOC es:\\n {df_mayor_1000_2}\")\n",
    "\n",
    "print(\"\\n --------------- \\n\")\n",
    "\n",
    "# filtramos con ILOC\n",
    "df_mayor_1000_iloc = df.iloc[list(df.Oro > 1000), :]\n",
    "print(f\"El resultado usando la sintaxis de df['COLUMNA'] usando ILOC es:\\n {df_mayor_1000_iloc}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Y si queremos que se cumplan varias condiciones?**\n",
    "\n",
    "En este caso tendremos que usar los operadores `&` o `|`, como vimos en NumPy. Recordemos lo que significan: \n",
    "\n",
    "- `&`: es como el operador `and`. En este caso se tendrán que cumplir todas las condiciones que le pasemos. \n",
    "\n",
    "- `|`: es como el operador `or`. En este caso nos devolverá datos de las condiciones que se cumplan, pero tienen porque cumplirse todas a la vez. O una condición y otra. \n",
    "\n",
    "En este ejercicio vamos a querer filtrar  los países que tengan menos de 100 medallas de Oro  y más de 900 de Bronce. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El resultado usando LOC es:\n",
      " Empty DataFrame\n",
      "Columns: [Oro, Plata, Bronce]\n",
      "Index: []\n",
      "\n",
      " --------------- \n",
      "\n",
      "El resultado usando ILOC es:\n",
      " Empty DataFrame\n",
      "Columns: [Oro, Plata, Bronce]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Seleccionar aquellas filas donde se cumpla la condición de que el viento es mayor que 20 y el tiempo era soleado.\n",
    "# además estamos especificando que nos devuelva solo las columnas de \"Temperature\" y \" Wind\"\n",
    "# SE TIENEN QUE CUMPLIR LAS DOS CONDICIONES\n",
    "\n",
    "# filtramos con LOC\n",
    "df_dos_condiciones_loc = df.loc[(df.Oro < 100) & (df.Bronce > 900), :]\n",
    "\n",
    "# filtramos con ILOC\n",
    "df_dos_condiciones_iloc = df.iloc[list((df.Oro < 100) & (df.Bronce > 900)), :]\n",
    "\n",
    "\n",
    "print(f\"El resultado usando LOC es:\\n {df_dos_condiciones_loc}\")\n",
    "\n",
    "print(\"\\n --------------- \\n\")\n",
    "\n",
    "print(f\"El resultado usando ILOC es:\\n {df_dos_condiciones_iloc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El resultado usando LOC es:\n",
      "                   Oro  Plata  Bronce\n",
      "País                                \n",
      "Japón            1032   1037     985\n",
      "China Taipéi       99    144     276\n",
      "Corea del Norte    91    120     235\n",
      "\n",
      " --------------- \n",
      "\n",
      "El resultado usando ILOC es:\n",
      "                   Oro  Plata  Bronce\n",
      "País                                \n",
      "Japón            1032   1037     985\n",
      "China Taipéi       99    144     276\n",
      "Corea del Norte    91    120     235\n"
     ]
    }
   ],
   "source": [
    "# hagámoslo ahora con un or (|)\n",
    "# SE TIENE QUE CUMPLIR UNA CONDICIÓN U OTRA\n",
    "\n",
    "# filtramos con LOC\n",
    "df_dos_condiciones_loc_or = df.loc[(df.Oro < 100) | (df.Bronce > 900), :]\n",
    "\n",
    "# filtramos con ILOC\n",
    "df_dos_condiciones_iloc_or = df.iloc[list((df.Oro < 100) | (df.Bronce > 900)), :]\n",
    "\n",
    "\n",
    "print(f\"El resultado usando LOC es:\\n {df_dos_condiciones_loc_or}\")\n",
    "\n",
    "print(\"\\n --------------- \\n\")\n",
    "\n",
    "print(f\"El resultado usando ILOC es:\\n {df_dos_condiciones_iloc_or}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**POR LO TANTO, LAS DIFERENCIAS ENTRE `LOC` E `ILOC` SON:**\n",
    "\n",
    "|       | loc                                             | iloc                                                |\n",
    "|-------|-------------------------------------------------|-----------------------------------------------------|\n",
    "| Uso   | Acceso a datos utilizando etiquetas de índice    | Acceso a datos utilizando posiciones de índice       |\n",
    "| Índice| Puede utilizar etiquetas o slices de etiquetas   | Solo puede utilizar posiciones enteras o slices      |\n",
    "| Filtrado | Permite filtrar filas y seleccionar columnas     | Permite filtrar filas y seleccionar columnas         |\n",
    "| Sintaxis | Utiliza etiquetas separadas por comas           | Utiliza posiciones enteras separadas por comas       |\n",
    "| Ejemplo | `df.loc[3:5, 'columna']`                        | `df.iloc[3:5, 2]`                                   |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Tabla de Contenidos",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "326.663px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
